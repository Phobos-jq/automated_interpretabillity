{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading tokenizer and model...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d10950d05a04370a4d4ec224a89c297",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model and tokenizer loaded.\n",
      "now using llama to simulate\n",
      "now using llama to simulate\n",
      "now using llama to simulate\n",
      "now using llama to simulate\n",
      "now using llama to simulate\n",
      "now using llama to simulate\n",
      "now using llama to simulate\n",
      "now using llama to simulate\n",
      "now using llama to simulate\n",
      "now using llama to simulate\n",
      "now _get_activation_stats_for_single_token_llama\n",
      "start generating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs['scores']=(tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]]),)\n",
      "len(outputs.sequences[0])=1198\n",
      "now _get_activation_stats_for_single_token_llama\n",
      "start generating\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"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\"\n",
    "neuron_records_path = \"/data/jqliu/ML_jq/nanoGPT/activations/ori_136000it/neuron_records_featuress.json\"\n",
    "\n",
    "from neuron_explainer.activations.activation_records import calculate_max_activation\n",
    "from neuron_explainer.activations.activations import ActivationRecordSliceParams, load_neuron\n",
    "from neuron_explainer.explanations.calibrated_simulator import UncalibratedNeuronSimulator\n",
    "from neuron_explainer.explanations.explainer import TokenActivationPairExplainer\n",
    "from neuron_explainer.explanations.prompt_builder import PromptFormat\n",
    "from neuron_explainer.explanations.scoring import simulate_and_score\n",
    "from neuron_explainer.explanations.simulator import ExplanationNeuronSimulator, ExplanationTokenByTokenSimulator\n",
    "\n",
    "EXPLAINER_MODEL_NAME = \"gpt-4\"\n",
    "# SIMULATOR_MODEL_NAME = \"davinci-002\"\n",
    "# SIMULATOR_MODEL_NAME = \"gpt-3.5-turbo-1106\"\n",
    "# SIMULATOR_MODEL_NAME = \"gpt-3.5-turbo-instruct\"\n",
    "SIMULATOR_MODEL_NAME = \"meta-llama/Meta-Llama-3-8B-Instruct\"\n",
    "TEST_NUM = 24  # 要抽取测试的神经元数量\n",
    "SEED = 42  # 设置随机种子，确保可复现性\n",
    "\n",
    "# 设置随机种子\n",
    "random.seed(SEED)\n",
    "\n",
    "# # 创建字典以记录结果\n",
    "# results = {}\n",
    "\n",
    "# # 随机抽取神经元编号\n",
    "# random_neuron_indices = random.sample(range(768), TEST_NUM)\n",
    "# total_score = 0.0\n",
    "\n",
    "# print(\"=========================\")\n",
    "# print(f\"{neuron_records_path=}\")\n",
    "# print(f\"{random_neuron_indices=}\")\n",
    "# print(\"=========================\")\n",
    "\n",
    "\n",
    "# for neuron_idx in random_neuron_indices:\n",
    "#     print(f\"now evaluating feature_{neuron_idx}\")\n",
    "#     # 加载神经元记录\n",
    "#     neuron_record = load_neuron(0, neuron_idx, neuron_records_path)\n",
    "    \n",
    "#     # 获取激活记录\n",
    "#     slice_params = ActivationRecordSliceParams(n_examples_per_split=5)\n",
    "#     train_activation_records = neuron_record.train_activation_records(\n",
    "#         activation_record_slice_params=slice_params\n",
    "#     )\n",
    "#     valid_activation_records = neuron_record.valid_activation_records(\n",
    "#         activation_record_slice_params=slice_params\n",
    "#     )\n",
    "\n",
    "#     # 生成神经元解释\n",
    "#     explainer = TokenActivationPairExplainer(\n",
    "#         model_name=EXPLAINER_MODEL_NAME,\n",
    "#         prompt_format=PromptFormat.HARMONY_V4,\n",
    "#         max_concurrent=1,\n",
    "#     )\n",
    "#     explanations = await explainer.generate_explanations(\n",
    "#         all_activation_records=train_activation_records,\n",
    "#         max_activation=calculate_max_activation(train_activation_records),\n",
    "#         num_samples=1,\n",
    "#     )\n",
    "#     assert len(explanations) == 1\n",
    "#     explanation = explanations[0]\n",
    "#     print(f\"Neuron {neuron_idx} explanation: {explanation}\")\n",
    "\n",
    "\n",
    "#     # 模拟并计算得分\n",
    "#     simulator = UncalibratedNeuronSimulator(\n",
    "#         ExplanationTokenByTokenSimulator(\n",
    "#             SIMULATOR_MODEL_NAME,\n",
    "#             explanation,\n",
    "#             max_concurrent=1,\n",
    "#             prompt_format=PromptFormat.INSTRUCTION_FOLLOWING,\n",
    "#         )\n",
    "#     )\n",
    "#     scored_simulation = await simulate_and_score(simulator, valid_activation_records)\n",
    "#     score = scored_simulation.get_preferred_score()\n",
    "#     print(f\"Neuron {neuron_idx} score: {score:.2f}\")\n",
    "    \n",
    "#     # 将结果存入字典\n",
    "#     results[neuron_idx] = {\n",
    "#         \"explanation\": explanation,\n",
    "#         \"score\": score\n",
    "#     }\n",
    "#     total_score += score\n",
    "\n",
    "# # 计算平均得分\n",
    "# average_score = total_score / TEST_NUM\n",
    "# print(\"Finished\")\n",
    "# print(f\"\\nAverage score for {TEST_NUM} neurons: {average_score:.2f}\")\n",
    "\n",
    "# # 打印所有结果\n",
    "# print(\"\\nResults for each neuron:\")\n",
    "# for neuron_idx, data in results.items():\n",
    "#     print(f\"Neuron {neuron_idx}: Explanation: {data['explanation']}, Score: {data['score']:.2f}\")\n",
    "\n",
    "\n",
    "# test_response = await client.make_request(prompt=\"test 123<|endofprompt|>\", max_tokens=2)\n",
    "# print(\"Response:\", test_response[\"choices\"][0][\"text\"])\n",
    "\n",
    "# Load a neuron record.\n",
    "neuron_record = load_neuron(0, 114, neuron_records_path)\n",
    "\n",
    "# Grab the activation records we'll need.\n",
    "slice_params = ActivationRecordSliceParams(n_examples_per_split=5)\n",
    "train_activation_records = neuron_record.train_activation_records(\n",
    "    activation_record_slice_params=slice_params\n",
    ")\n",
    "valid_activation_records = neuron_record.valid_activation_records(\n",
    "    activation_record_slice_params=slice_params\n",
    ")\n",
    "\n",
    "# # Generate an explanation for the neuron.\n",
    "# explainer = TokenActivationPairExplainer(\n",
    "#     model_name=EXPLAINER_MODEL_NAME,\n",
    "#     prompt_format=PromptFormat.HARMONY_V4,\n",
    "#     max_concurrent=1,\n",
    "# )\n",
    "# explanations = await explainer.generate_explanations(\n",
    "#     all_activation_records=train_activation_records,\n",
    "#     max_activation=calculate_max_activation(train_activation_records),\n",
    "#     num_samples=1,\n",
    "# )\n",
    "# assert len(explanations) == 1\n",
    "# explanation = explanations[0]\n",
    "# print(f\"{explanation=}\")\n",
    "\n",
    "explanation=\"names and references that end with 'ac'.\"\n",
    "\n",
    "# Simulate and score the explanation.\n",
    "simulator = UncalibratedNeuronSimulator(\n",
    "    ExplanationTokenByTokenSimulator(\n",
    "        SIMULATOR_MODEL_NAME,\n",
    "        explanation,\n",
    "        max_concurrent=1,\n",
    "        prompt_format=PromptFormat.INSTRUCTION_FOLLOWING,\n",
    "    )\n",
    ")\n",
    "scored_simulation = await simulate_and_score(simulator, valid_activation_records)\n",
    "print(f\"score={scored_simulation.get_preferred_score():.2f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3.9_autoInter",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
