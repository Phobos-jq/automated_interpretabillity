{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We're studying neurons in a neural network.\n",
      "Each neuron looks for some particular thing in a short document.\n",
      "Look at summary of what the neuron does, and try to predict how it will fire on each token.\n",
      "\n",
      "The activation format is token<tab>activation, activations go from 0 to 10, \"unknown\" indicates an unknown activation. Most activations will be 0.\n",
      "\n",
      "\n",
      "Neuron 1\n",
      "Explanation of neuron 1 behavior: the main thing this neuron does is find present tense verbs ending in 'ing'\n",
      "Activations: \n",
      "<start>\n",
      "t\tunknown\n",
      "urt\tunknown\n",
      "ur\tunknown\n",
      "ro\tunknown\n",
      " is\tunknown\n",
      " fab\tunknown\n",
      "ulously\tunknown\n",
      " funny\tunknown\n",
      " and\tunknown\n",
      " over\tunknown\n",
      " the\t0\n",
      " top\t0\n",
      " as\t0\n",
      " a\t0\n",
      " '\t0\n",
      "very\t0\n",
      " sneaky\t0\n",
      "'\t1\n",
      " but\t0\n",
      "ler\t0\n",
      " who\t0\n",
      " excel\t0\n",
      "s\t0\n",
      " in\t0\n",
      " the\t0\n",
      " art\t0\n",
      " of\t0\n",
      " impossible\t0\n",
      " disappearing\t6\n",
      "/\t0\n",
      "re\t0\n",
      "app\t0\n",
      "earing\t10\n",
      " acts\t0\n",
      "<end>\n",
      "<start>\n",
      "esc\tunknown\n",
      "aping\tunknown\n",
      " the\tunknown\n",
      " studio\t0\n",
      " ,\t0\n",
      " pic\t0\n",
      "col\t0\n",
      "i\t0\n",
      " is\t0\n",
      " warm\t0\n",
      "ly\t0\n",
      " affecting\t3\n",
      " and\t0\n",
      " so\t0\n",
      " is\t0\n",
      " this\t0\n",
      " ad\t0\n",
      "roit\t0\n",
      "ly\t0\n",
      " minimalist\t0\n",
      " movie\t0\n",
      " .\t0\n",
      "<end>\n",
      "\n",
      "\n",
      "\n",
      "Neuron 2\n",
      "Explanation of neuron 2 behavior: the main thing this neuron does is find words related to physical medical conditions\n",
      "Activations: \n",
      "<start>\n",
      "as\tunknown\n",
      " sac\tunknown\n",
      "char\tunknown\n",
      "ine\tunknown\n",
      " movies\tunknown\n",
      " go\t0\n",
      " ,\t0\n",
      " this\t0\n",
      " is\t0\n",
      " likely\t0\n",
      " to\t0\n",
      " cause\t0\n",
      " massive\t0\n",
      " cardiac\t0\n",
      " arrest\t10\n",
      " if\t0\n",
      " taken\t0\n",
      " in\t0\n",
      " large\t0\n",
      " doses\t0\n",
      " .\t0\n",
      "<end>\n",
      "<start>\n",
      "shot\tunknown\n",
      " perhaps\tunknown\n",
      " '\tunknown\n",
      "art\tunknown\n",
      "istically\tunknown\n",
      "'\tunknown\n",
      " with\tunknown\n",
      " handheld\tunknown\n",
      " cameras\tunknown\n",
      " and\tunknown\n",
      " apparently\tunknown\n",
      " no\tunknown\n",
      " movie\tunknown\n",
      " lights\tunknown\n",
      " by\tunknown\n",
      " jo\tunknown\n",
      "aquin\tunknown\n",
      " b\tunknown\n",
      "aca\tunknown\n",
      "-\tunknown\n",
      "as\t0\n",
      "ay\t0\n",
      " ,\t0\n",
      " the\t0\n",
      " low\t0\n",
      "-\t0\n",
      "budget\t0\n",
      " production\t0\n",
      " swings\t0\n",
      " annoy\t0\n",
      "ingly\t0\n",
      " between\t0\n",
      " vert\t0\n",
      "igo\t9\n",
      " and\t0\n",
      " opacity\t0\n",
      " .\t0\n",
      "<end>\n",
      "\n",
      "\n",
      "\n",
      "Neuron 3\n",
      "Explanation of neuron 3 behavior: the main thing this neuron does is find phrases related to community\n",
      "Activations: \n",
      "<start>\n",
      "the\t0\n",
      " sense\t0\n",
      " of\t0\n",
      " together\t3\n",
      "ness\t7\n",
      " in\t0\n",
      " our\t0\n",
      " town\t1\n",
      " is\t0\n",
      " strong\t0\n",
      " .\t0\n",
      "<end>\n",
      "<start>\n",
      "a\tunknown\n",
      " buoy\tunknown\n",
      "ant\tunknown\n",
      " romantic\tunknown\n",
      " comedy\tunknown\n",
      " about\tunknown\n",
      " friendship\tunknown\n",
      " ,\tunknown\n",
      " love\tunknown\n",
      " ,\tunknown\n",
      " and\t0\n",
      " the\t0\n",
      " truth\t0\n",
      " that\t0\n",
      " we\t2\n",
      "'re\t4\n",
      " all\t3\n",
      " in\t7\n",
      " this\t10\n",
      " together\t5\n",
      " .\t0\n",
      "<end>\n",
      "\n",
      "\n",
      "\n",
      "Neuron 4\n",
      "Explanation of neuron 4 behavior: the main thing this neuron does is find words and phrases related to sports competitions and events.<|endofprompt|>\n",
      "Activations: \n",
      "<start>\n",
      "Seattle\tunknown\n",
      " enters\tunknown\n",
      " a\tunknown\n",
      " pivotal\tunknown\n",
      " early\tunknown\n",
      " season\tunknown\n",
      " matchup\tunknown\n",
      " against\tunknown\n",
      " the\tunknown\n",
      " Tennessee\tunknown\n",
      " Titans\tunknown\n",
      " with\tunknown\n",
      " major\tunknown\n",
      " questions\tunknown\n",
      " on\tunknown\n",
      " offense\tunknown\n",
      ".\tunknown\n",
      " They\tunknown\n",
      " have\tunknown\n",
      " in\tunknown\n",
      "arg\tunknown\n",
      "uably\tunknown\n",
      " been\tunknown\n",
      " one\tunknown\n",
      " of\tunknown\n",
      " the\tunknown\n",
      " worst\tunknown\n",
      " offenses\tunknown\n",
      " in\tunknown\n",
      " the\tunknown\n",
      " NFL\tunknown\n",
      " through\tunknown\n",
      " two\tunknown\n",
      " weeks\tunknown\n",
      ",\tunknown\n",
      " and\tunknown\n",
      " will\tunknown\n",
      " need\tunknown\n",
      " to\tunknown\n",
      " take\tunknown\n",
      " a\tunknown\n",
      " significant\tunknown\n",
      " step\tunknown\n",
      " forward\tunknown\n",
      " against\tunknown\n",
      " an\tunknown\n",
      " efficient\tunknown\n",
      " Titans\tunknown\n",
      " offense\tunknown\n",
      " that\tunknown\n",
      " will\tunknown\n",
      " be\tunknown\n",
      " difficult\tunknown\n",
      " to\tunknown\n",
      " hold\tunknown\n",
      " down\tunknown\n",
      " playing\tunknown\n",
      " in\tunknown\n",
      " front\tunknown\n",
      " of\tunknown\n",
      " their\tunknown\n",
      " home\tunknown\n",
      " crowd\tunknown\n",
      ".\tunknown\n",
      "<end>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('We\\'re studying neurons in a neural network.\\nEach neuron looks for some particular thing in a short document.\\nLook at summary of what the neuron does, and try to predict how it will fire on each token.\\n\\nThe activation format is token<tab>activation, activations go from 0 to 10, \"unknown\" indicates an unknown activation. Most activations will be 0.\\n\\n\\nNeuron 1\\nExplanation of neuron 1 behavior: the main thing this neuron does is find present tense verbs ending in \\'ing\\'\\nActivations: \\n<start>\\nt\\tunknown\\nurt\\tunknown\\nur\\tunknown\\nro\\tunknown\\n is\\tunknown\\n fab\\tunknown\\nulously\\tunknown\\n funny\\tunknown\\n and\\tunknown\\n over\\tunknown\\n the\\t0\\n top\\t0\\n as\\t0\\n a\\t0\\n \\'\\t0\\nvery\\t0\\n sneaky\\t0\\n\\'\\t1\\n but\\t0\\nler\\t0\\n who\\t0\\n excel\\t0\\ns\\t0\\n in\\t0\\n the\\t0\\n art\\t0\\n of\\t0\\n impossible\\t0\\n disappearing\\t6\\n/\\t0\\nre\\t0\\napp\\t0\\nearing\\t10\\n acts\\t0\\n<end>\\n<start>\\nesc\\tunknown\\naping\\tunknown\\n the\\tunknown\\n studio\\t0\\n ,\\t0\\n pic\\t0\\ncol\\t0\\ni\\t0\\n is\\t0\\n warm\\t0\\nly\\t0\\n affecting\\t3\\n and\\t0\\n so\\t0\\n is\\t0\\n this\\t0\\n ad\\t0\\nroit\\t0\\nly\\t0\\n minimalist\\t0\\n movie\\t0\\n .\\t0\\n<end>\\n\\n\\n\\nNeuron 2\\nExplanation of neuron 2 behavior: the main thing this neuron does is find words related to physical medical conditions\\nActivations: \\n<start>\\nas\\tunknown\\n sac\\tunknown\\nchar\\tunknown\\nine\\tunknown\\n movies\\tunknown\\n go\\t0\\n ,\\t0\\n this\\t0\\n is\\t0\\n likely\\t0\\n to\\t0\\n cause\\t0\\n massive\\t0\\n cardiac\\t0\\n arrest\\t10\\n if\\t0\\n taken\\t0\\n in\\t0\\n large\\t0\\n doses\\t0\\n .\\t0\\n<end>\\n<start>\\nshot\\tunknown\\n perhaps\\tunknown\\n \\'\\tunknown\\nart\\tunknown\\nistically\\tunknown\\n\\'\\tunknown\\n with\\tunknown\\n handheld\\tunknown\\n cameras\\tunknown\\n and\\tunknown\\n apparently\\tunknown\\n no\\tunknown\\n movie\\tunknown\\n lights\\tunknown\\n by\\tunknown\\n jo\\tunknown\\naquin\\tunknown\\n b\\tunknown\\naca\\tunknown\\n-\\tunknown\\nas\\t0\\nay\\t0\\n ,\\t0\\n the\\t0\\n low\\t0\\n-\\t0\\nbudget\\t0\\n production\\t0\\n swings\\t0\\n annoy\\t0\\ningly\\t0\\n between\\t0\\n vert\\t0\\nigo\\t9\\n and\\t0\\n opacity\\t0\\n .\\t0\\n<end>\\n\\n\\n\\nNeuron 3\\nExplanation of neuron 3 behavior: the main thing this neuron does is find phrases related to community\\nActivations: \\n<start>\\nthe\\t0\\n sense\\t0\\n of\\t0\\n together\\t3\\nness\\t7\\n in\\t0\\n our\\t0\\n town\\t1\\n is\\t0\\n strong\\t0\\n .\\t0\\n<end>\\n<start>\\na\\tunknown\\n buoy\\tunknown\\nant\\tunknown\\n romantic\\tunknown\\n comedy\\tunknown\\n about\\tunknown\\n friendship\\tunknown\\n ,\\tunknown\\n love\\tunknown\\n ,\\tunknown\\n and\\t0\\n the\\t0\\n truth\\t0\\n that\\t0\\n we\\t2\\n\\'re\\t4\\n all\\t3\\n in\\t7\\n this\\t10\\n together\\t5\\n .\\t0\\n<end>\\n\\n\\n\\nNeuron 4\\nExplanation of neuron 4 behavior: the main thing this neuron does is find words and phrases related to sports competitions and events.<|endofprompt|>\\nActivations: \\n<start>\\nSeattle\\tunknown\\n enters\\tunknown\\n a\\tunknown\\n pivotal\\tunknown\\n early\\tunknown\\n season\\tunknown\\n matchup\\tunknown\\n against\\tunknown\\n the\\tunknown\\n Tennessee\\tunknown\\n Titans\\tunknown\\n with\\tunknown\\n major\\tunknown\\n questions\\tunknown\\n on\\tunknown\\n offense\\tunknown\\n.\\tunknown\\n They\\tunknown\\n have\\tunknown\\n in\\tunknown\\narg\\tunknown\\nuably\\tunknown\\n been\\tunknown\\n one\\tunknown\\n of\\tunknown\\n the\\tunknown\\n worst\\tunknown\\n offenses\\tunknown\\n in\\tunknown\\n the\\tunknown\\n NFL\\tunknown\\n through\\tunknown\\n two\\tunknown\\n weeks\\tunknown\\n,\\tunknown\\n and\\tunknown\\n will\\tunknown\\n need\\tunknown\\n to\\tunknown\\n take\\tunknown\\n a\\tunknown\\n significant\\tunknown\\n step\\tunknown\\n forward\\tunknown\\n against\\tunknown\\n an\\tunknown\\n efficient\\tunknown\\n Titans\\tunknown\\n offense\\tunknown\\n that\\tunknown\\n will\\tunknown\\n be\\tunknown\\n difficult\\tunknown\\n to\\tunknown\\n hold\\tunknown\\n down\\tunknown\\n playing\\tunknown\\n in\\tunknown\\n front\\tunknown\\n of\\tunknown\\n their\\tunknown\\n home\\tunknown\\n crowd\\tunknown\\n.\\tunknown\\n<end>\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<start>\n",
      "Raph\tunknown\n",
      "ael\tunknown\n",
      " M\tunknown\n",
      "arc\tunknown\n",
      "hand\tunknown\n",
      " Vs\tunknown\n",
      " .\tunknown\n",
      " D\tunknown\n",
      "a\tunknown\n",
      "rek\tunknown\n",
      " Thr\tunknown\n",
      "ead\tunknown\n",
      "s\tunknown\n",
      " VS\tunknown\n",
      " S\tunknown\n",
      "hem\tunknown\n",
      "ihj\tunknown\n",
      " W\tunknown\n",
      "illiam\tunknown\n",
      "s\tunknown\n",
      " II\tunknown\n",
      "The\tunknown\n",
      "Raphael\t5\n",
      " Marchand\tcan\t0\n",
      " become\t0\n",
      " the\t0\n",
      " most\t0\n",
      " annoying\t0\n",
      " offensive\t0\n",
      " player\t0\n",
      " to\t0\n",
      " Evgeni\t0\n",
      " Malkin\t0\n",
      " with\t0\n",
      " his\t0\n",
      " speed\t0\n",
      " and\t0\n",
      " ball\t0\n",
      "-\t0\n",
      "handling\t0\n",
      ",\t0\n",
      " but\t0\n",
      "the\t0\n",
      " comparisons\t0\n",
      " will\t0\n",
      " not\t0\n",
      " fear\t0\n",
      " as\t0\n",
      " frankly\t0\n",
      " ,\t0\n",
      " the\t0\n",
      " kid\t0\n",
      " seems\thigh\t\n",
      "\n",
      "<end>\n"
     ]
    }
   ],
   "source": [
    "print('<start>\\nRaph\\tunknown\\nael\\tunknown\\n M\\tunknown\\narc\\tunknown\\nhand\\tunknown\\n Vs\\tunknown\\n .\\tunknown\\n D\\tunknown\\na\\tunknown\\nrek\\tunknown\\n Thr\\tunknown\\nead\\tunknown\\ns\\tunknown\\n VS\\tunknown\\n S\\tunknown\\nhem\\tunknown\\nihj\\tunknown\\n W\\tunknown\\nilliam\\tunknown\\ns\\tunknown\\n II\\tunknown\\nThe\\tunknown\\nRaphael\\t5\\n Marchand\\tcan\\t0\\n become\\t0\\n the\\t0\\n most\\t0\\n annoying\\t0\\n offensive\\t0\\n player\\t0\\n to\\t0\\n Evgeni\\t0\\n Malkin\\t0\\n with\\t0\\n his\\t0\\n speed\\t0\\n and\\t0\\n ball\\t0\\n-\\t0\\nhandling\\t0\\n,\\t0\\n but\\t0\\nthe\\t0\\n comparisons\\t0\\n will\\t0\\n not\\t0\\n fear\\t0\\n as\\t0\\n frankly\\t0\\n ,\\t0\\n the\\t0\\n kid\\t0\\n seems\\thigh\\t\\n\\n<end>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<start>\n",
      "The\tunknown\n",
      " archer\t10\n",
      "y\t9\n",
      " championship\t5\n",
      " in\t0\n",
      " our\t0\n",
      " county\t7\n",
      " is\tunknown\n",
      " sanctioned\t10\n",
      " by\t0\n",
      " a\t0\n",
      " myriad\t2\n",
      " of\t0\n",
      " professional\t5\n",
      " associations\t10\n",
      ".\t0\n",
      " It\t0\n",
      "'s\t0\n",
      " time\t0\n",
      " to\t0\n",
      " unleash\t10\n",
      " your\t0\n",
      " inner\t0\n",
      " ch\t10\n",
      "ampion\t9\n",
      " !\t0\n",
      "<end>\n"
     ]
    }
   ],
   "source": [
    "print(\"<start>\\nThe\\tunknown\\n archer\\t10\\ny\\t9\\n championship\\t5\\n in\\t0\\n our\\t0\\n county\\t7\\n is\\tunknown\\n sanctioned\\t10\\n by\\t0\\n a\\t0\\n myriad\\t2\\n of\\t0\\n professional\\t5\\n associations\\t10\\n.\\t0\\n It\\t0\\n's\\t0\\n time\\t0\\n to\\t0\\n unleash\\t10\\n your\\t0\\n inner\\t0\\n ch\\t10\\nampion\\t9\\n !\\t0\\n<end>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We're studying neurons in a neural network.\n",
      "Each neuron looks for some particular thing in a short document.\n",
      "Look at summary of what the neuron does, and try to predict how it will fire on each token.\n",
      "\n",
      "The activation format is token<tab>activation, activations go from 0 to 10, \"unknown\" indicates an unknown activation. Most activations will be 0.\n",
      "\n",
      "\n",
      "Neuron 1\n",
      "Explanation of neuron 1 behavior: the main thing this neuron does is find present tense verbs ending in 'ing'\n",
      "Activations: \n",
      "<start>\n",
      "t\tunknown\n",
      "urt\tunknown\n",
      "ur\tunknown\n",
      "ro\tunknown\n",
      " is\tunknown\n",
      " fab\tunknown\n",
      "ulously\tunknown\n",
      " funny\tunknown\n",
      " and\tunknown\n",
      " over\tunknown\n",
      " the\t0\n",
      " top\t0\n",
      " as\t0\n",
      " a\t0\n",
      " '\t0\n",
      "very\t0\n",
      " sneaky\t0\n",
      "'\t1\n",
      " but\t0\n",
      "ler\t0\n",
      " who\t0\n",
      " excel\t0\n",
      "s\t0\n",
      " in\t0\n",
      " the\t0\n",
      " art\t0\n",
      " of\t0\n",
      " impossible\t0\n",
      " disappearing\t6\n",
      "/\t0\n",
      "re\t0\n",
      "app\t0\n",
      "earing\t10\n",
      " acts\t0\n",
      "<end>\n",
      "<start>\n",
      "esc\tunknown\n",
      "aping\tunknown\n",
      " the\tunknown\n",
      " studio\t0\n",
      " ,\t0\n",
      " pic\t0\n",
      "col\t0\n",
      "i\t0\n",
      " is\t0\n",
      " warm\t0\n",
      "ly\t0\n",
      " affecting\t3\n",
      " and\t0\n",
      " so\t0\n",
      " is\t0\n",
      " this\t0\n",
      " ad\t0\n",
      "roit\t0\n",
      "ly\t0\n",
      " minimalist\t0\n",
      " movie\t0\n",
      " .\t0\n",
      "<end>\n",
      "\n",
      "\n",
      "\n",
      "Neuron 2\n",
      "Explanation of neuron 2 behavior: the main thing this neuron does is find words related to physical medical conditions\n",
      "Activations: \n",
      "<start>\n",
      "as\tunknown\n",
      " sac\tunknown\n",
      "char\tunknown\n",
      "ine\tunknown\n",
      " movies\tunknown\n",
      " go\t0\n",
      " ,\t0\n",
      " this\t0\n",
      " is\t0\n",
      " likely\t0\n",
      " to\t0\n",
      " cause\t0\n",
      " massive\t0\n",
      " cardiac\t0\n",
      " arrest\t10\n",
      " if\t0\n",
      " taken\t0\n",
      " in\t0\n",
      " large\t0\n",
      " doses\t0\n",
      " .\t0\n",
      "<end>\n",
      "<start>\n",
      "shot\tunknown\n",
      " perhaps\tunknown\n",
      " '\tunknown\n",
      "art\tunknown\n",
      "istically\tunknown\n",
      "'\tunknown\n",
      " with\tunknown\n",
      " handheld\tunknown\n",
      " cameras\tunknown\n",
      " and\tunknown\n",
      " apparently\tunknown\n",
      " no\tunknown\n",
      " movie\tunknown\n",
      " lights\tunknown\n",
      " by\tunknown\n",
      " jo\tunknown\n",
      "aquin\tunknown\n",
      " b\tunknown\n",
      "aca\tunknown\n",
      "-\tunknown\n",
      "as\t0\n",
      "ay\t0\n",
      " ,\t0\n",
      " the\t0\n",
      " low\t0\n",
      "-\t0\n",
      "budget\t0\n",
      " production\t0\n",
      " swings\t0\n",
      " annoy\t0\n",
      "ingly\t0\n",
      " between\t0\n",
      " vert\t0\n",
      "igo\t9\n",
      " and\t0\n",
      " opacity\t0\n",
      " .\t0\n",
      "<end>\n",
      "\n",
      "\n",
      "\n",
      "Neuron 3\n",
      "Explanation of neuron 3 behavior: the main thing this neuron does is find phrases related to community\n",
      "Activations: \n",
      "<start>\n",
      "the\t0\n",
      " sense\t0\n",
      " of\t0\n",
      " together\t3\n",
      "ness\t7\n",
      " in\t0\n",
      " our\t0\n",
      " town\t1\n",
      " is\t0\n",
      " strong\t0\n",
      " .\t0\n",
      "<end>\n",
      "<start>\n",
      "a\tunknown\n",
      " buoy\tunknown\n",
      "ant\tunknown\n",
      " romantic\tunknown\n",
      " comedy\tunknown\n",
      " about\tunknown\n",
      " friendship\tunknown\n",
      " ,\tunknown\n",
      " love\tunknown\n",
      " ,\tunknown\n",
      " and\t0\n",
      " the\t0\n",
      " truth\t0\n",
      " that\t0\n",
      " we\t2\n",
      "'re\t4\n",
      " all\t3\n",
      " in\t7\n",
      " this\t10\n",
      " together\t5\n",
      " .\t0\n",
      "<end>\n",
      "\n",
      "\n",
      "\n",
      "Neuron 4\n",
      "Explanation of neuron 4 behavior: the main thing this neuron does is find words and phrases related to sports competitions and events.<|endofprompt|>\n",
      "Activations: \n",
      "<start>\n",
      "Seattle\tunknown\n",
      " enters\tunknown\n",
      " a\tunknown\n",
      " pivotal\tunknown\n",
      " early\tunknown\n",
      " season\tunknown\n",
      " matchup\tunknown\n",
      " against\tunknown\n",
      " the\tunknown\n",
      " Tennessee\tunknown\n",
      " Titans\tunknown\n",
      " with\tunknown\n",
      " major\tunknown\n",
      " questions\tunknown\n",
      " on\tunknown\n",
      " offense\tunknown\n",
      ".\tunknown\n",
      " They\tunknown\n",
      " have\tunknown\n",
      " in\tunknown\n",
      "arg\tunknown\n",
      "uably\tunknown\n",
      " been\tunknown\n",
      " one\tunknown\n",
      " of\tunknown\n",
      " the\tunknown\n",
      " worst\tunknown\n",
      " offenses\tunknown\n",
      " in\tunknown\n",
      " the\tunknown\n",
      " NFL\tunknown\n",
      " through\tunknown\n",
      " two\tunknown\n",
      " weeks\tunknown\n",
      ",\tunknown\n",
      " and\tunknown\n",
      " will\tunknown\n",
      " need\tunknown\n",
      " to\tunknown\n",
      " take\tunknown\n",
      " a\tunknown\n",
      " significant\tunknown\n",
      " step\tunknown\n",
      " forward\tunknown\n",
      " against\tunknown\n",
      " an\tunknown\n",
      " efficient\tunknown\n",
      " Titans\tunknown\n",
      " offense\tunknown\n",
      " that\tunknown\n",
      " will\tunknown\n",
      " be\tunknown\n",
      " difficult\tunknown\n",
      " to\tunknown\n",
      " hold\tunknown\n",
      " down\tunknown\n",
      " playing\tunknown\n",
      " in\tunknown\n",
      " front\tunknown\n",
      " of\tunknown\n",
      " their\tunknown\n",
      " home\tunknown\n",
      " crowd\tunknown\n",
      ".\tunknown\n",
      "<end>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('We\\'re studying neurons in a neural network.\\nEach neuron looks for some particular thing in a short document.\\nLook at summary of what the neuron does, and try to predict how it will fire on each token.\\n\\nThe activation format is token<tab>activation, activations go from 0 to 10, \"unknown\" indicates an unknown activation. Most activations will be 0.\\n\\n\\nNeuron 1\\nExplanation of neuron 1 behavior: the main thing this neuron does is find present tense verbs ending in \\'ing\\'\\nActivations: \\n<start>\\nt\\tunknown\\nurt\\tunknown\\nur\\tunknown\\nro\\tunknown\\n is\\tunknown\\n fab\\tunknown\\nulously\\tunknown\\n funny\\tunknown\\n and\\tunknown\\n over\\tunknown\\n the\\t0\\n top\\t0\\n as\\t0\\n a\\t0\\n \\'\\t0\\nvery\\t0\\n sneaky\\t0\\n\\'\\t1\\n but\\t0\\nler\\t0\\n who\\t0\\n excel\\t0\\ns\\t0\\n in\\t0\\n the\\t0\\n art\\t0\\n of\\t0\\n impossible\\t0\\n disappearing\\t6\\n/\\t0\\nre\\t0\\napp\\t0\\nearing\\t10\\n acts\\t0\\n<end>\\n<start>\\nesc\\tunknown\\naping\\tunknown\\n the\\tunknown\\n studio\\t0\\n ,\\t0\\n pic\\t0\\ncol\\t0\\ni\\t0\\n is\\t0\\n warm\\t0\\nly\\t0\\n affecting\\t3\\n and\\t0\\n so\\t0\\n is\\t0\\n this\\t0\\n ad\\t0\\nroit\\t0\\nly\\t0\\n minimalist\\t0\\n movie\\t0\\n .\\t0\\n<end>\\n\\n\\n\\nNeuron 2\\nExplanation of neuron 2 behavior: the main thing this neuron does is find words related to physical medical conditions\\nActivations: \\n<start>\\nas\\tunknown\\n sac\\tunknown\\nchar\\tunknown\\nine\\tunknown\\n movies\\tunknown\\n go\\t0\\n ,\\t0\\n this\\t0\\n is\\t0\\n likely\\t0\\n to\\t0\\n cause\\t0\\n massive\\t0\\n cardiac\\t0\\n arrest\\t10\\n if\\t0\\n taken\\t0\\n in\\t0\\n large\\t0\\n doses\\t0\\n .\\t0\\n<end>\\n<start>\\nshot\\tunknown\\n perhaps\\tunknown\\n \\'\\tunknown\\nart\\tunknown\\nistically\\tunknown\\n\\'\\tunknown\\n with\\tunknown\\n handheld\\tunknown\\n cameras\\tunknown\\n and\\tunknown\\n apparently\\tunknown\\n no\\tunknown\\n movie\\tunknown\\n lights\\tunknown\\n by\\tunknown\\n jo\\tunknown\\naquin\\tunknown\\n b\\tunknown\\naca\\tunknown\\n-\\tunknown\\nas\\t0\\nay\\t0\\n ,\\t0\\n the\\t0\\n low\\t0\\n-\\t0\\nbudget\\t0\\n production\\t0\\n swings\\t0\\n annoy\\t0\\ningly\\t0\\n between\\t0\\n vert\\t0\\nigo\\t9\\n and\\t0\\n opacity\\t0\\n .\\t0\\n<end>\\n\\n\\n\\nNeuron 3\\nExplanation of neuron 3 behavior: the main thing this neuron does is find phrases related to community\\nActivations: \\n<start>\\nthe\\t0\\n sense\\t0\\n of\\t0\\n together\\t3\\nness\\t7\\n in\\t0\\n our\\t0\\n town\\t1\\n is\\t0\\n strong\\t0\\n .\\t0\\n<end>\\n<start>\\na\\tunknown\\n buoy\\tunknown\\nant\\tunknown\\n romantic\\tunknown\\n comedy\\tunknown\\n about\\tunknown\\n friendship\\tunknown\\n ,\\tunknown\\n love\\tunknown\\n ,\\tunknown\\n and\\t0\\n the\\t0\\n truth\\t0\\n that\\t0\\n we\\t2\\n\\'re\\t4\\n all\\t3\\n in\\t7\\n this\\t10\\n together\\t5\\n .\\t0\\n<end>\\n\\n\\n\\nNeuron 4\\nExplanation of neuron 4 behavior: the main thing this neuron does is find words and phrases related to sports competitions and events.<|endofprompt|>\\nActivations: \\n<start>\\nSeattle\\tunknown\\n enters\\tunknown\\n a\\tunknown\\n pivotal\\tunknown\\n early\\tunknown\\n season\\tunknown\\n matchup\\tunknown\\n against\\tunknown\\n the\\tunknown\\n Tennessee\\tunknown\\n Titans\\tunknown\\n with\\tunknown\\n major\\tunknown\\n questions\\tunknown\\n on\\tunknown\\n offense\\tunknown\\n.\\tunknown\\n They\\tunknown\\n have\\tunknown\\n in\\tunknown\\narg\\tunknown\\nuably\\tunknown\\n been\\tunknown\\n one\\tunknown\\n of\\tunknown\\n the\\tunknown\\n worst\\tunknown\\n offenses\\tunknown\\n in\\tunknown\\n the\\tunknown\\n NFL\\tunknown\\n through\\tunknown\\n two\\tunknown\\n weeks\\tunknown\\n,\\tunknown\\n and\\tunknown\\n will\\tunknown\\n need\\tunknown\\n to\\tunknown\\n take\\tunknown\\n a\\tunknown\\n significant\\tunknown\\n step\\tunknown\\n forward\\tunknown\\n against\\tunknown\\n an\\tunknown\\n efficient\\tunknown\\n Titans\\tunknown\\n offense\\tunknown\\n that\\tunknown\\n will\\tunknown\\n be\\tunknown\\n difficult\\tunknown\\n to\\tunknown\\n hold\\tunknown\\n down\\tunknown\\n playing\\tunknown\\n in\\tunknown\\n front\\tunknown\\n of\\tunknown\\n their\\tunknown\\n home\\tunknown\\n crowd\\tunknown\\n.\\tunknown\\n<end>\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We're studying neurons in a neural network. Each neuron looks for some particular thing in a short document. Look at  an explanation of what the neuron does, and try to predict its activations on a particular token.\n",
      "\n",
      "The activation format is token<tab>activation, and activations range from 0 to 10. Most activations will be 0.\n",
      "\n",
      "Neuron 1\n",
      "Explanation of neuron 1 behavior: the main thing this neuron does is find language related to something being groundbreaking\n",
      "Activations: \n",
      "<start>\n",
      "The\t0\n",
      " editors\t0\n",
      " of\t0\n",
      " Bi\t0\n",
      "opol\t0\n",
      "ym\t0\n",
      "ers\t0\n",
      " are\t0\n",
      " delighted\t0\n",
      " to\t0\n",
      " present\t0\n",
      " the\t0\n",
      " \t0\n",
      "201\t0\n",
      "8\t0\n",
      " Murray\t0\n",
      " Goodman\t0\n",
      " Memorial\t0\n",
      " Prize\t0\n",
      " to\t0\n",
      " Professor\t0\n",
      " David\t0\n",
      " N\t0\n",
      ".\t0\n",
      " Ber\t0\n",
      "atan\t0\n",
      " in\t0\n",
      " recognition\t0\n",
      " of\t0\n",
      " his\t0\n",
      " seminal\t10\n",
      " contributions\t0\n",
      " to\t0\n",
      " bi\t0\n",
      "oph\t0\n",
      "ysics\t0\n",
      " and\t0\n",
      " their\t0\n",
      " impact\t0\n",
      " on\t0\n",
      " our\t0\n",
      " understanding\t0\n",
      " of\t0\n",
      " charge\t0\n",
      " transport\t0\n",
      " in\t0\n",
      " biom\t0\n",
      "olecules\t0\n",
      ".\n",
      "\n",
      "\t0\n",
      "In\t0\n",
      "aug\t0\n",
      "ur\t0\n",
      "ated\t0\n",
      " in\t0\n",
      " \t0\n",
      "200\t0\n",
      "7\t0\n",
      " in\t0\n",
      " honor\t0\n",
      " of\t0\n",
      " the\t0\n",
      " Bi\t0\n",
      "opol\t0\n",
      "ym\t0\n",
      "ers\t0\n",
      " Found\t0\n",
      "ing\t1\n",
      " Editor\t0\n",
      ",\t0\n",
      " the\t0\n",
      " prize\t0\n",
      " is\t0\n",
      " awarded\t0\n",
      " for\t0\n",
      " outstanding\t0\n",
      " accomplishments\t0\n",
      "<end>\n",
      "\n",
      "\n",
      "Neuron 2\n",
      "Explanation of neuron 2 behavior: the main thing this neuron does is find the word “variant” and other words with the same ”vari” root\n",
      "Activations: \n",
      "<start>\n",
      "{\"\t0\n",
      "widget\t0\n",
      "Class\t0\n",
      "\":\"\t0\n",
      "Variant\t6\n",
      "Matrix\t0\n",
      "Widget\t0\n",
      "\",\"\t0\n",
      "back\t0\n",
      "order\t0\n",
      "Message\t0\n",
      "\":\"\t0\n",
      "Back\t0\n",
      "ordered\t0\n",
      "\",\"\t0\n",
      "back\t0\n",
      "order\t0\n",
      "Message\t0\n",
      "Single\t0\n",
      "Variant\t5\n",
      "\":\"\t0\n",
      "This\t0\n",
      " item\t0\n",
      " is\t0\n",
      " back\t0\n",
      "ordered\t0\n",
      ".\",\"\t0\n",
      "ordered\t0\n",
      "Selection\t0\n",
      "\":\t0\n",
      "true\t0\n",
      ",\"\t0\n",
      "product\t0\n",
      "Variant\t5\n",
      "Id\t0\n",
      "\":\t0\n",
      "0\t0\n",
      ",\"\t0\n",
      "variant\t6\n",
      "Id\t0\n",
      "Field\t0\n",
      "\":\"\t0\n",
      "product\t0\n",
      "196\t0\n",
      "39\t0\n",
      "_V\t5\n",
      "ariant\t5\n",
      "Id\t0\n",
      "\",\"\t0\n",
      "back\t0\n",
      "order\t0\n",
      "To\t0\n",
      "Message\t0\n",
      "Single\t0\n",
      "Variant\t4\n",
      "\":\"\t0\n",
      "This\t0\n",
      " item\t0\n",
      " is\t0\n",
      " back\t0\n",
      "ordered\t0\n",
      " and\t0\n",
      " is\t0\n",
      " expected\t0\n",
      " by\t0\n",
      " {\t0\n",
      "0\t0\n",
      "}.\t0\n",
      "\",\"\t0\n",
      "low\t0\n",
      "Price\t0\n",
      "\":\t0\n",
      "999\t0\n",
      "9\t0\n",
      ".\t0\n",
      "0\t0\n",
      ",\"\t0\n",
      "attribute\t0\n",
      "Indexes\t0\n",
      "\":[\t0\n",
      "],\"\t0\n",
      "productId\t0\n",
      "\":\t0\n",
      "196\t0\n",
      "39\t0\n",
      ",\"\t0\n",
      "price\t0\n",
      "V\t3\n",
      "ariance\t3\n",
      "\":\t0\n",
      "true\t0\n",
      ",\"\t0\n",
      "<end>\n",
      "<start>\n",
      "A\t0\n",
      " regular\t0\n",
      " look\t0\n",
      " at\t0\n",
      " the\t0\n",
      " ups\t0\n",
      " and\t0\n",
      " downs\t0\n",
      " of\t0\n",
      " variant\t9\n",
      " covers\t0\n",
      " in\t0\n",
      " the\t0\n",
      " comics\t0\n",
      " industry\t0\n",
      "…\n",
      "\n",
      "\t0\n",
      "Here\t0\n",
      " are\t0\n",
      " the\t0\n",
      " Lego\t0\n",
      " variant\t2\n",
      " sketch\t0\n",
      " covers\t0\n",
      " by\t0\n",
      " Leon\t0\n",
      "el\t0\n",
      " Cast\t0\n",
      "ell\t0\n",
      "ani\t0\n",
      " for\t0\n",
      " a\t0\n",
      " variety\t4\n",
      " of\t0\n",
      " Marvel\t0\n",
      " titles\t0\n",
      ",\t0\n",
      "<end>\n",
      "\n",
      "\n",
      "Now, we're going predict the activation of a new neuron on a single token, following the same rules as the examples above. Activations still range from 0 to 10.\n",
      "Neuron 3\n",
      "Explanation of neuron 3 behavior: the main thing this neuron does is find words and phrases related to sports competitions and events.\n",
      "Text:\n",
      "B10 111 MONDAY, FEBRUARY 11, 2019 DONATE\n",
      "\n",
      "Last token in the text:\n",
      "ATE\n",
      "\n",
      "Last token activation, considering the token in the context in which it appeared in the text:\n",
      "8\n",
      "\n",
      "\n",
      "Neuron 4\n",
      "Explanation of neuron 4 behavior: the main thing this neuron does is find words and phrases related to sports competitions and events.\n",
      "Text:\n",
      "Seattle enters a pivotal early season matchup against the Tennessee Titans with major questions on offense. They have inarguably been one of the worst offenses in the NFL through two weeks, and will need to take a significant step forward against an efficient Titans offense that will be difficult to hold down playing in front of their home crowd.\n",
      "\n",
      "Last token in the text:\n",
      ".\n",
      "\n",
      "Last token activation, considering the token in the context in which it appeared in the text:\n",
      "<|endofprompt|>\n"
     ]
    }
   ],
   "source": [
    "print('We\\'re studying neurons in a neural network. Each neuron looks for some particular thing in a short document. Look at  an explanation of what the neuron does, and try to predict its activations on a particular token.\\n\\nThe activation format is token<tab>activation, and activations range from 0 to 10. Most activations will be 0.\\n\\nNeuron 1\\nExplanation of neuron 1 behavior: the main thing this neuron does is find language related to something being groundbreaking\\nActivations: \\n<start>\\nThe\\t0\\n editors\\t0\\n of\\t0\\n Bi\\t0\\nopol\\t0\\nym\\t0\\ners\\t0\\n are\\t0\\n delighted\\t0\\n to\\t0\\n present\\t0\\n the\\t0\\n \\t0\\n201\\t0\\n8\\t0\\n Murray\\t0\\n Goodman\\t0\\n Memorial\\t0\\n Prize\\t0\\n to\\t0\\n Professor\\t0\\n David\\t0\\n N\\t0\\n.\\t0\\n Ber\\t0\\natan\\t0\\n in\\t0\\n recognition\\t0\\n of\\t0\\n his\\t0\\n seminal\\t10\\n contributions\\t0\\n to\\t0\\n bi\\t0\\noph\\t0\\nysics\\t0\\n and\\t0\\n their\\t0\\n impact\\t0\\n on\\t0\\n our\\t0\\n understanding\\t0\\n of\\t0\\n charge\\t0\\n transport\\t0\\n in\\t0\\n biom\\t0\\nolecules\\t0\\n.\\n\\n\\t0\\nIn\\t0\\naug\\t0\\nur\\t0\\nated\\t0\\n in\\t0\\n \\t0\\n200\\t0\\n7\\t0\\n in\\t0\\n honor\\t0\\n of\\t0\\n the\\t0\\n Bi\\t0\\nopol\\t0\\nym\\t0\\ners\\t0\\n Found\\t0\\ning\\t1\\n Editor\\t0\\n,\\t0\\n the\\t0\\n prize\\t0\\n is\\t0\\n awarded\\t0\\n for\\t0\\n outstanding\\t0\\n accomplishments\\t0\\n<end>\\n\\n\\nNeuron 2\\nExplanation of neuron 2 behavior: the main thing this neuron does is find the word “variant” and other words with the same ”vari” root\\nActivations: \\n<start>\\n{\"\\t0\\nwidget\\t0\\nClass\\t0\\n\":\"\\t0\\nVariant\\t6\\nMatrix\\t0\\nWidget\\t0\\n\",\"\\t0\\nback\\t0\\norder\\t0\\nMessage\\t0\\n\":\"\\t0\\nBack\\t0\\nordered\\t0\\n\",\"\\t0\\nback\\t0\\norder\\t0\\nMessage\\t0\\nSingle\\t0\\nVariant\\t5\\n\":\"\\t0\\nThis\\t0\\n item\\t0\\n is\\t0\\n back\\t0\\nordered\\t0\\n.\",\"\\t0\\nordered\\t0\\nSelection\\t0\\n\":\\t0\\ntrue\\t0\\n,\"\\t0\\nproduct\\t0\\nVariant\\t5\\nId\\t0\\n\":\\t0\\n0\\t0\\n,\"\\t0\\nvariant\\t6\\nId\\t0\\nField\\t0\\n\":\"\\t0\\nproduct\\t0\\n196\\t0\\n39\\t0\\n_V\\t5\\nariant\\t5\\nId\\t0\\n\",\"\\t0\\nback\\t0\\norder\\t0\\nTo\\t0\\nMessage\\t0\\nSingle\\t0\\nVariant\\t4\\n\":\"\\t0\\nThis\\t0\\n item\\t0\\n is\\t0\\n back\\t0\\nordered\\t0\\n and\\t0\\n is\\t0\\n expected\\t0\\n by\\t0\\n {\\t0\\n0\\t0\\n}.\\t0\\n\",\"\\t0\\nlow\\t0\\nPrice\\t0\\n\":\\t0\\n999\\t0\\n9\\t0\\n.\\t0\\n0\\t0\\n,\"\\t0\\nattribute\\t0\\nIndexes\\t0\\n\":[\\t0\\n],\"\\t0\\nproductId\\t0\\n\":\\t0\\n196\\t0\\n39\\t0\\n,\"\\t0\\nprice\\t0\\nV\\t3\\nariance\\t3\\n\":\\t0\\ntrue\\t0\\n,\"\\t0\\n<end>\\n<start>\\nA\\t0\\n regular\\t0\\n look\\t0\\n at\\t0\\n the\\t0\\n ups\\t0\\n and\\t0\\n downs\\t0\\n of\\t0\\n variant\\t9\\n covers\\t0\\n in\\t0\\n the\\t0\\n comics\\t0\\n industry\\t0\\n…\\n\\n\\t0\\nHere\\t0\\n are\\t0\\n the\\t0\\n Lego\\t0\\n variant\\t2\\n sketch\\t0\\n covers\\t0\\n by\\t0\\n Leon\\t0\\nel\\t0\\n Cast\\t0\\nell\\t0\\nani\\t0\\n for\\t0\\n a\\t0\\n variety\\t4\\n of\\t0\\n Marvel\\t0\\n titles\\t0\\n,\\t0\\n<end>\\n\\n\\nNow, we\\'re going predict the activation of a new neuron on a single token, following the same rules as the examples above. Activations still range from 0 to 10.\\nNeuron 3\\nExplanation of neuron 3 behavior: the main thing this neuron does is find words and phrases related to sports competitions and events.\\nText:\\nB10 111 MONDAY, FEBRUARY 11, 2019 DONATE\\n\\nLast token in the text:\\nATE\\n\\nLast token activation, considering the token in the context in which it appeared in the text:\\n8\\n\\n\\nNeuron 4\\nExplanation of neuron 4 behavior: the main thing this neuron does is find words and phrases related to sports competitions and events.\\nText:\\nSeattle enters a pivotal early season matchup against the Tennessee Titans with major questions on offense. They have inarguably been one of the worst offenses in the NFL through two weeks, and will need to take a significant step forward against an efficient Titans offense that will be difficult to hold down playing in front of their home crowd.\\n\\nLast token in the text:\\n.\\n\\nLast token activation, considering the token in the context in which it appeared in the text:\\n<|endofprompt|>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We're studying neurons in a neural network. Each neuron looks for some particular thing in a short document. Look at  an explanation of what the neuron does, and try to predict its activations on a particular token.\n",
      "\n",
      "The activation format is token<tab>activation, and activations range from 0 to 10. Most activations will be 0.\n",
      "\n",
      "Neuron 1\n",
      "Explanation of neuron 1 behavior: the main thing this neuron does is find language related to something being groundbreaking\n",
      "Activations: \n",
      "<start>\n",
      "The\t0\n",
      " editors\t0\n",
      " of\t0\n",
      " Bi\t0\n",
      "opol\t0\n",
      "ym\t0\n",
      "ers\t0\n",
      " are\t0\n",
      " delighted\t0\n",
      " to\t0\n",
      " present\t0\n",
      " the\t0\n",
      " \t0\n",
      "201\t0\n",
      "8\t0\n",
      " Murray\t0\n",
      " Goodman\t0\n",
      " Memorial\t0\n",
      " Prize\t0\n",
      " to\t0\n",
      " Professor\t0\n",
      " David\t0\n",
      " N\t0\n",
      ".\t0\n",
      " Ber\t0\n",
      "atan\t0\n",
      " in\t0\n",
      " recognition\t0\n",
      " of\t0\n",
      " his\t0\n",
      " seminal\t10\n",
      " contributions\t0\n",
      " to\t0\n",
      " bi\t0\n",
      "oph\t0\n",
      "ysics\t0\n",
      " and\t0\n",
      " their\t0\n",
      " impact\t0\n",
      " on\t0\n",
      " our\t0\n",
      " understanding\t0\n",
      " of\t0\n",
      " charge\t0\n",
      " transport\t0\n",
      " in\t0\n",
      " biom\t0\n",
      "olecules\t0\n",
      ".\n",
      "\n",
      "\t0\n",
      "In\t0\n",
      "aug\t0\n",
      "ur\t0\n",
      "ated\t0\n",
      " in\t0\n",
      " \t0\n",
      "200\t0\n",
      "7\t0\n",
      " in\t0\n",
      " honor\t0\n",
      " of\t0\n",
      " the\t0\n",
      " Bi\t0\n",
      "opol\t0\n",
      "ym\t0\n",
      "ers\t0\n",
      " Found\t0\n",
      "ing\t1\n",
      " Editor\t0\n",
      ",\t0\n",
      " the\t0\n",
      " prize\t0\n",
      " is\t0\n",
      " awarded\t0\n",
      " for\t0\n",
      " outstanding\t0\n",
      " accomplishments\t0\n",
      "<end>\n",
      "\n",
      "\n",
      "Neuron 2\n",
      "Explanation of neuron 2 behavior: the main thing this neuron does is find the word “variant” and other words with the same ”vari” root\n",
      "Activations: \n",
      "<start>\n",
      "{\"\t0\n",
      "widget\t0\n",
      "Class\t0\n",
      "\":\"\t0\n",
      "Variant\t6\n",
      "Matrix\t0\n",
      "Widget\t0\n",
      "\",\"\t0\n",
      "back\t0\n",
      "order\t0\n",
      "Message\t0\n",
      "\":\"\t0\n",
      "Back\t0\n",
      "ordered\t0\n",
      "\",\"\t0\n",
      "back\t0\n",
      "order\t0\n",
      "Message\t0\n",
      "Single\t0\n",
      "Variant\t5\n",
      "\":\"\t0\n",
      "This\t0\n",
      " item\t0\n",
      " is\t0\n",
      " back\t0\n",
      "ordered\t0\n",
      ".\",\"\t0\n",
      "ordered\t0\n",
      "Selection\t0\n",
      "\":\t0\n",
      "true\t0\n",
      ",\"\t0\n",
      "product\t0\n",
      "Variant\t5\n",
      "Id\t0\n",
      "\":\t0\n",
      "0\t0\n",
      ",\"\t0\n",
      "variant\t6\n",
      "Id\t0\n",
      "Field\t0\n",
      "\":\"\t0\n",
      "product\t0\n",
      "196\t0\n",
      "39\t0\n",
      "_V\t5\n",
      "ariant\t5\n",
      "Id\t0\n",
      "\",\"\t0\n",
      "back\t0\n",
      "order\t0\n",
      "To\t0\n",
      "Message\t0\n",
      "Single\t0\n",
      "Variant\t4\n",
      "\":\"\t0\n",
      "This\t0\n",
      " item\t0\n",
      " is\t0\n",
      " back\t0\n",
      "ordered\t0\n",
      " and\t0\n",
      " is\t0\n",
      " expected\t0\n",
      " by\t0\n",
      " {\t0\n",
      "0\t0\n",
      "}.\t0\n",
      "\",\"\t0\n",
      "low\t0\n",
      "Price\t0\n",
      "\":\t0\n",
      "999\t0\n",
      "9\t0\n",
      ".\t0\n",
      "0\t0\n",
      ",\"\t0\n",
      "attribute\t0\n",
      "Indexes\t0\n",
      "\":[\t0\n",
      "],\"\t0\n",
      "productId\t0\n",
      "\":\t0\n",
      "196\t0\n",
      "39\t0\n",
      ",\"\t0\n",
      "price\t0\n",
      "V\t3\n",
      "ariance\t3\n",
      "\":\t0\n",
      "true\t0\n",
      ",\"\t0\n",
      "<end>\n",
      "<start>\n",
      "A\t0\n",
      " regular\t0\n",
      " look\t0\n",
      " at\t0\n",
      " the\t0\n",
      " ups\t0\n",
      " and\t0\n",
      " downs\t0\n",
      " of\t0\n",
      " variant\t9\n",
      " covers\t0\n",
      " in\t0\n",
      " the\t0\n",
      " comics\t0\n",
      " industry\t0\n",
      "…\n",
      "\n",
      "\t0\n",
      "Here\t0\n",
      " are\t0\n",
      " the\t0\n",
      " Lego\t0\n",
      " variant\t2\n",
      " sketch\t0\n",
      " covers\t0\n",
      " by\t0\n",
      " Leon\t0\n",
      "el\t0\n",
      " Cast\t0\n",
      "ell\t0\n",
      "ani\t0\n",
      " for\t0\n",
      " a\t0\n",
      " variety\t4\n",
      " of\t0\n",
      " Marvel\t0\n",
      " titles\t0\n",
      ",\t0\n",
      "<end>\n",
      "\n",
      "\n",
      "Now, we're going predict the activation of a new neuron on a single token, following the same rules as the examples above. Activations still range from 0 to 10.\n",
      "Neuron 3\n",
      "Explanation of neuron 3 behavior: the main thing this neuron does is find words and phrases related to sports competitions and events.\n",
      "Text:\n",
      "B10 111 MONDAY, FEBRUARY 11, 2019 DONATE\n",
      "\n",
      "Last token in the text:\n",
      "ATE\n",
      "\n",
      "Last token activation, considering the token in the context in which it appeared in the text:\n",
      "8\n",
      "\n",
      "\n",
      "Neuron 4\n",
      "Explanation of neuron 4 behavior: the main thing this neuron does is find words and phrases related to sports competitions and events.\n",
      "Text:\n",
      "Seattle enters a\n",
      "\n",
      "Last token in the text:\n",
      " a\n",
      "\n",
      "Last token activation, considering the token in the context in which it appeared in the text:\n",
      "<|endofprompt|>\n"
     ]
    }
   ],
   "source": [
    "print('We\\'re studying neurons in a neural network. Each neuron looks for some particular thing in a short document. Look at  an explanation of what the neuron does, and try to predict its activations on a particular token.\\n\\nThe activation format is token<tab>activation, and activations range from 0 to 10. Most activations will be 0.\\n\\nNeuron 1\\nExplanation of neuron 1 behavior: the main thing this neuron does is find language related to something being groundbreaking\\nActivations: \\n<start>\\nThe\\t0\\n editors\\t0\\n of\\t0\\n Bi\\t0\\nopol\\t0\\nym\\t0\\ners\\t0\\n are\\t0\\n delighted\\t0\\n to\\t0\\n present\\t0\\n the\\t0\\n \\t0\\n201\\t0\\n8\\t0\\n Murray\\t0\\n Goodman\\t0\\n Memorial\\t0\\n Prize\\t0\\n to\\t0\\n Professor\\t0\\n David\\t0\\n N\\t0\\n.\\t0\\n Ber\\t0\\natan\\t0\\n in\\t0\\n recognition\\t0\\n of\\t0\\n his\\t0\\n seminal\\t10\\n contributions\\t0\\n to\\t0\\n bi\\t0\\noph\\t0\\nysics\\t0\\n and\\t0\\n their\\t0\\n impact\\t0\\n on\\t0\\n our\\t0\\n understanding\\t0\\n of\\t0\\n charge\\t0\\n transport\\t0\\n in\\t0\\n biom\\t0\\nolecules\\t0\\n.\\n\\n\\t0\\nIn\\t0\\naug\\t0\\nur\\t0\\nated\\t0\\n in\\t0\\n \\t0\\n200\\t0\\n7\\t0\\n in\\t0\\n honor\\t0\\n of\\t0\\n the\\t0\\n Bi\\t0\\nopol\\t0\\nym\\t0\\ners\\t0\\n Found\\t0\\ning\\t1\\n Editor\\t0\\n,\\t0\\n the\\t0\\n prize\\t0\\n is\\t0\\n awarded\\t0\\n for\\t0\\n outstanding\\t0\\n accomplishments\\t0\\n<end>\\n\\n\\nNeuron 2\\nExplanation of neuron 2 behavior: the main thing this neuron does is find the word “variant” and other words with the same ”vari” root\\nActivations: \\n<start>\\n{\"\\t0\\nwidget\\t0\\nClass\\t0\\n\":\"\\t0\\nVariant\\t6\\nMatrix\\t0\\nWidget\\t0\\n\",\"\\t0\\nback\\t0\\norder\\t0\\nMessage\\t0\\n\":\"\\t0\\nBack\\t0\\nordered\\t0\\n\",\"\\t0\\nback\\t0\\norder\\t0\\nMessage\\t0\\nSingle\\t0\\nVariant\\t5\\n\":\"\\t0\\nThis\\t0\\n item\\t0\\n is\\t0\\n back\\t0\\nordered\\t0\\n.\",\"\\t0\\nordered\\t0\\nSelection\\t0\\n\":\\t0\\ntrue\\t0\\n,\"\\t0\\nproduct\\t0\\nVariant\\t5\\nId\\t0\\n\":\\t0\\n0\\t0\\n,\"\\t0\\nvariant\\t6\\nId\\t0\\nField\\t0\\n\":\"\\t0\\nproduct\\t0\\n196\\t0\\n39\\t0\\n_V\\t5\\nariant\\t5\\nId\\t0\\n\",\"\\t0\\nback\\t0\\norder\\t0\\nTo\\t0\\nMessage\\t0\\nSingle\\t0\\nVariant\\t4\\n\":\"\\t0\\nThis\\t0\\n item\\t0\\n is\\t0\\n back\\t0\\nordered\\t0\\n and\\t0\\n is\\t0\\n expected\\t0\\n by\\t0\\n {\\t0\\n0\\t0\\n}.\\t0\\n\",\"\\t0\\nlow\\t0\\nPrice\\t0\\n\":\\t0\\n999\\t0\\n9\\t0\\n.\\t0\\n0\\t0\\n,\"\\t0\\nattribute\\t0\\nIndexes\\t0\\n\":[\\t0\\n],\"\\t0\\nproductId\\t0\\n\":\\t0\\n196\\t0\\n39\\t0\\n,\"\\t0\\nprice\\t0\\nV\\t3\\nariance\\t3\\n\":\\t0\\ntrue\\t0\\n,\"\\t0\\n<end>\\n<start>\\nA\\t0\\n regular\\t0\\n look\\t0\\n at\\t0\\n the\\t0\\n ups\\t0\\n and\\t0\\n downs\\t0\\n of\\t0\\n variant\\t9\\n covers\\t0\\n in\\t0\\n the\\t0\\n comics\\t0\\n industry\\t0\\n…\\n\\n\\t0\\nHere\\t0\\n are\\t0\\n the\\t0\\n Lego\\t0\\n variant\\t2\\n sketch\\t0\\n covers\\t0\\n by\\t0\\n Leon\\t0\\nel\\t0\\n Cast\\t0\\nell\\t0\\nani\\t0\\n for\\t0\\n a\\t0\\n variety\\t4\\n of\\t0\\n Marvel\\t0\\n titles\\t0\\n,\\t0\\n<end>\\n\\n\\nNow, we\\'re going predict the activation of a new neuron on a single token, following the same rules as the examples above. Activations still range from 0 to 10.\\nNeuron 3\\nExplanation of neuron 3 behavior: the main thing this neuron does is find words and phrases related to sports competitions and events.\\nText:\\nB10 111 MONDAY, FEBRUARY 11, 2019 DONATE\\n\\nLast token in the text:\\nATE\\n\\nLast token activation, considering the token in the context in which it appeared in the text:\\n8\\n\\n\\nNeuron 4\\nExplanation of neuron 4 behavior: the main thing this neuron does is find words and phrases related to sports competitions and events.\\nText:\\nSeattle enters a\\n\\nLast token in the text:\\n a\\n\\nLast token activation, considering the token in the context in which it appeared in the text:\\n<|endofprompt|>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We're studying neurons in a neural network. Each neuron looks for some particular thing in a short document. Look at  an explanation of what the neuron does, and try to predict its activations on a particular token.\n",
      "\n",
      "The activation format is token<tab>activation, and activations range from 0 to 10. Most activations will be 0.\n",
      "\n",
      "Neuron 1\n",
      "Explanation of neuron 1 behavior: the main thing this neuron does is find language related to something being groundbreaking\n",
      "Activations: \n",
      "<start>\n",
      "The\t0\n",
      " editors\t0\n",
      " of\t0\n",
      " Bi\t0\n",
      "opol\t0\n",
      "ym\t0\n",
      "ers\t0\n",
      " are\t0\n",
      " delighted\t0\n",
      " to\t0\n",
      " present\t0\n",
      " the\t0\n",
      " \t0\n",
      "201\t0\n",
      "8\t0\n",
      " Murray\t0\n",
      " Goodman\t0\n",
      " Memorial\t0\n",
      " Prize\t0\n",
      " to\t0\n",
      " Professor\t0\n",
      " David\t0\n",
      " N\t0\n",
      ".\t0\n",
      " Ber\t0\n",
      "atan\t0\n",
      " in\t0\n",
      " recognition\t0\n",
      " of\t0\n",
      " his\t0\n",
      " seminal\t10\n",
      " contributions\t0\n",
      " to\t0\n",
      " bi\t0\n",
      "oph\t0\n",
      "ysics\t0\n",
      " and\t0\n",
      " their\t0\n",
      " impact\t0\n",
      " on\t0\n",
      " our\t0\n",
      " understanding\t0\n",
      " of\t0\n",
      " charge\t0\n",
      " transport\t0\n",
      " in\t0\n",
      " biom\t0\n",
      "olecules\t0\n",
      ".\n",
      "\n",
      "\t0\n",
      "In\t0\n",
      "aug\t0\n",
      "ur\t0\n",
      "ated\t0\n",
      " in\t0\n",
      " \t0\n",
      "200\t0\n",
      "7\t0\n",
      " in\t0\n",
      " honor\t0\n",
      " of\t0\n",
      " the\t0\n",
      " Bi\t0\n",
      "opol\t0\n",
      "ym\t0\n",
      "ers\t0\n",
      " Found\t0\n",
      "ing\t1\n",
      " Editor\t0\n",
      ",\t0\n",
      " the\t0\n",
      " prize\t0\n",
      " is\t0\n",
      " awarded\t0\n",
      " for\t0\n",
      " outstanding\t0\n",
      " accomplishments\t0\n",
      "<end>\n",
      "\n",
      "\n",
      "Neuron 2\n",
      "Explanation of neuron 2 behavior: the main thing this neuron does is find the word “variant” and other words with the same ”vari” root\n",
      "Activations: \n",
      "<start>\n",
      "{\"\t0\n",
      "widget\t0\n",
      "Class\t0\n",
      "\":\"\t0\n",
      "Variant\t6\n",
      "Matrix\t0\n",
      "Widget\t0\n",
      "\",\"\t0\n",
      "back\t0\n",
      "order\t0\n",
      "Message\t0\n",
      "\":\"\t0\n",
      "Back\t0\n",
      "ordered\t0\n",
      "\",\"\t0\n",
      "back\t0\n",
      "order\t0\n",
      "Message\t0\n",
      "Single\t0\n",
      "Variant\t5\n",
      "\":\"\t0\n",
      "This\t0\n",
      " item\t0\n",
      " is\t0\n",
      " back\t0\n",
      "ordered\t0\n",
      ".\",\"\t0\n",
      "ordered\t0\n",
      "Selection\t0\n",
      "\":\t0\n",
      "true\t0\n",
      ",\"\t0\n",
      "product\t0\n",
      "Variant\t5\n",
      "Id\t0\n",
      "\":\t0\n",
      "0\t0\n",
      ",\"\t0\n",
      "variant\t6\n",
      "Id\t0\n",
      "Field\t0\n",
      "\":\"\t0\n",
      "product\t0\n",
      "196\t0\n",
      "39\t0\n",
      "_V\t5\n",
      "ariant\t5\n",
      "Id\t0\n",
      "\",\"\t0\n",
      "back\t0\n",
      "order\t0\n",
      "To\t0\n",
      "Message\t0\n",
      "Single\t0\n",
      "Variant\t4\n",
      "\":\"\t0\n",
      "This\t0\n",
      " item\t0\n",
      " is\t0\n",
      " back\t0\n",
      "ordered\t0\n",
      " and\t0\n",
      " is\t0\n",
      " expected\t0\n",
      " by\t0\n",
      " {\t0\n",
      "0\t0\n",
      "}.\t0\n",
      "\",\"\t0\n",
      "low\t0\n",
      "Price\t0\n",
      "\":\t0\n",
      "999\t0\n",
      "9\t0\n",
      ".\t0\n",
      "0\t0\n",
      ",\"\t0\n",
      "attribute\t0\n",
      "Indexes\t0\n",
      "\":[\t0\n",
      "],\"\t0\n",
      "productId\t0\n",
      "\":\t0\n",
      "196\t0\n",
      "39\t0\n",
      ",\"\t0\n",
      "price\t0\n",
      "V\t3\n",
      "ariance\t3\n",
      "\":\t0\n",
      "true\t0\n",
      ",\"\t0\n",
      "<end>\n",
      "<start>\n",
      "A\t0\n",
      " regular\t0\n",
      " look\t0\n",
      " at\t0\n",
      " the\t0\n",
      " ups\t0\n",
      " and\t0\n",
      " downs\t0\n",
      " of\t0\n",
      " variant\t9\n",
      " covers\t0\n",
      " in\t0\n",
      " the\t0\n",
      " comics\t0\n",
      " industry\t0\n",
      "…\n",
      "\n",
      "\t0\n",
      "Here\t0\n",
      " are\t0\n",
      " the\t0\n",
      " Lego\t0\n",
      " variant\t2\n",
      " sketch\t0\n",
      " covers\t0\n",
      " by\t0\n",
      " Leon\t0\n",
      "el\t0\n",
      " Cast\t0\n",
      "ell\t0\n",
      "ani\t0\n",
      " for\t0\n",
      " a\t0\n",
      " variety\t4\n",
      " of\t0\n",
      " Marvel\t0\n",
      " titles\t0\n",
      ",\t0\n",
      "<end>\n",
      "\n",
      "\n",
      "Now, we're going predict the activation of a new neuron on a single token, following the same rules as the examples above. Activations still range from 0 to 10.\n",
      "Neuron 3\n",
      "Explanation of neuron 3 behavior: the main thing this neuron does is find words and phrases related to sports competitions and events.\n",
      "Text:\n",
      "B10 111 MONDAY, FEBRUARY 11, 2019 DONATE\n",
      "\n",
      "Last token in the text:\n",
      "ATE\n",
      "\n",
      "Last token activation, considering the token in the context in which it appeared in the text:\n",
      "8\n",
      "\n",
      "\n",
      "Neuron 4\n",
      "Explanation of neuron 4 behavior: the main thing this neuron does is find words and phrases related to sports competitions and events.\n",
      "Text:\n",
      "Seattle enters a pivotal\n",
      "\n",
      "Last token in the text:\n",
      " pivotal\n",
      "\n",
      "Last token activation, considering the token in the context in which it appeared in the text:\n",
      "<|endofprompt|>\n"
     ]
    }
   ],
   "source": [
    "print('We\\'re studying neurons in a neural network. Each neuron looks for some particular thing in a short document. Look at  an explanation of what the neuron does, and try to predict its activations on a particular token.\\n\\nThe activation format is token<tab>activation, and activations range from 0 to 10. Most activations will be 0.\\n\\nNeuron 1\\nExplanation of neuron 1 behavior: the main thing this neuron does is find language related to something being groundbreaking\\nActivations: \\n<start>\\nThe\\t0\\n editors\\t0\\n of\\t0\\n Bi\\t0\\nopol\\t0\\nym\\t0\\ners\\t0\\n are\\t0\\n delighted\\t0\\n to\\t0\\n present\\t0\\n the\\t0\\n \\t0\\n201\\t0\\n8\\t0\\n Murray\\t0\\n Goodman\\t0\\n Memorial\\t0\\n Prize\\t0\\n to\\t0\\n Professor\\t0\\n David\\t0\\n N\\t0\\n.\\t0\\n Ber\\t0\\natan\\t0\\n in\\t0\\n recognition\\t0\\n of\\t0\\n his\\t0\\n seminal\\t10\\n contributions\\t0\\n to\\t0\\n bi\\t0\\noph\\t0\\nysics\\t0\\n and\\t0\\n their\\t0\\n impact\\t0\\n on\\t0\\n our\\t0\\n understanding\\t0\\n of\\t0\\n charge\\t0\\n transport\\t0\\n in\\t0\\n biom\\t0\\nolecules\\t0\\n.\\n\\n\\t0\\nIn\\t0\\naug\\t0\\nur\\t0\\nated\\t0\\n in\\t0\\n \\t0\\n200\\t0\\n7\\t0\\n in\\t0\\n honor\\t0\\n of\\t0\\n the\\t0\\n Bi\\t0\\nopol\\t0\\nym\\t0\\ners\\t0\\n Found\\t0\\ning\\t1\\n Editor\\t0\\n,\\t0\\n the\\t0\\n prize\\t0\\n is\\t0\\n awarded\\t0\\n for\\t0\\n outstanding\\t0\\n accomplishments\\t0\\n<end>\\n\\n\\nNeuron 2\\nExplanation of neuron 2 behavior: the main thing this neuron does is find the word “variant” and other words with the same ”vari” root\\nActivations: \\n<start>\\n{\"\\t0\\nwidget\\t0\\nClass\\t0\\n\":\"\\t0\\nVariant\\t6\\nMatrix\\t0\\nWidget\\t0\\n\",\"\\t0\\nback\\t0\\norder\\t0\\nMessage\\t0\\n\":\"\\t0\\nBack\\t0\\nordered\\t0\\n\",\"\\t0\\nback\\t0\\norder\\t0\\nMessage\\t0\\nSingle\\t0\\nVariant\\t5\\n\":\"\\t0\\nThis\\t0\\n item\\t0\\n is\\t0\\n back\\t0\\nordered\\t0\\n.\",\"\\t0\\nordered\\t0\\nSelection\\t0\\n\":\\t0\\ntrue\\t0\\n,\"\\t0\\nproduct\\t0\\nVariant\\t5\\nId\\t0\\n\":\\t0\\n0\\t0\\n,\"\\t0\\nvariant\\t6\\nId\\t0\\nField\\t0\\n\":\"\\t0\\nproduct\\t0\\n196\\t0\\n39\\t0\\n_V\\t5\\nariant\\t5\\nId\\t0\\n\",\"\\t0\\nback\\t0\\norder\\t0\\nTo\\t0\\nMessage\\t0\\nSingle\\t0\\nVariant\\t4\\n\":\"\\t0\\nThis\\t0\\n item\\t0\\n is\\t0\\n back\\t0\\nordered\\t0\\n and\\t0\\n is\\t0\\n expected\\t0\\n by\\t0\\n {\\t0\\n0\\t0\\n}.\\t0\\n\",\"\\t0\\nlow\\t0\\nPrice\\t0\\n\":\\t0\\n999\\t0\\n9\\t0\\n.\\t0\\n0\\t0\\n,\"\\t0\\nattribute\\t0\\nIndexes\\t0\\n\":[\\t0\\n],\"\\t0\\nproductId\\t0\\n\":\\t0\\n196\\t0\\n39\\t0\\n,\"\\t0\\nprice\\t0\\nV\\t3\\nariance\\t3\\n\":\\t0\\ntrue\\t0\\n,\"\\t0\\n<end>\\n<start>\\nA\\t0\\n regular\\t0\\n look\\t0\\n at\\t0\\n the\\t0\\n ups\\t0\\n and\\t0\\n downs\\t0\\n of\\t0\\n variant\\t9\\n covers\\t0\\n in\\t0\\n the\\t0\\n comics\\t0\\n industry\\t0\\n…\\n\\n\\t0\\nHere\\t0\\n are\\t0\\n the\\t0\\n Lego\\t0\\n variant\\t2\\n sketch\\t0\\n covers\\t0\\n by\\t0\\n Leon\\t0\\nel\\t0\\n Cast\\t0\\nell\\t0\\nani\\t0\\n for\\t0\\n a\\t0\\n variety\\t4\\n of\\t0\\n Marvel\\t0\\n titles\\t0\\n,\\t0\\n<end>\\n\\n\\nNow, we\\'re going predict the activation of a new neuron on a single token, following the same rules as the examples above. Activations still range from 0 to 10.\\nNeuron 3\\nExplanation of neuron 3 behavior: the main thing this neuron does is find words and phrases related to sports competitions and events.\\nText:\\nB10 111 MONDAY, FEBRUARY 11, 2019 DONATE\\n\\nLast token in the text:\\nATE\\n\\nLast token activation, considering the token in the context in which it appeared in the text:\\n8\\n\\n\\nNeuron 4\\nExplanation of neuron 4 behavior: the main thing this neuron does is find words and phrases related to sports competitions and events.\\nText:\\nSeattle enters a pivotal\\n\\nLast token in the text:\\n pivotal\\n\\nLast token activation, considering the token in the context in which it appeared in the text:\\n<|endofprompt|>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We're studying neurons in a neural network. Each neuron looks for some particular thing in a short document. Look at  an explanation of what the neuron does, and try to predict its activations on a particular token.\n",
      "\n",
      "The activation format is token<tab>activation, and activations range from 0 to 10. Most activations will be 0.\n",
      "\n",
      "Neuron 1\n",
      "Explanation of neuron 1 behavior: the main thing this neuron does is find language related to something being groundbreaking\n",
      "Activations: \n",
      "<start>\n",
      "The\t0\n",
      " editors\t0\n",
      " of\t0\n",
      " Bi\t0\n",
      "opol\t0\n",
      "ym\t0\n",
      "ers\t0\n",
      " are\t0\n",
      " delighted\t0\n",
      " to\t0\n",
      " present\t0\n",
      " the\t0\n",
      " \t0\n",
      "201\t0\n",
      "8\t0\n",
      " Murray\t0\n",
      " Goodman\t0\n",
      " Memorial\t0\n",
      " Prize\t0\n",
      " to\t0\n",
      " Professor\t0\n",
      " David\t0\n",
      " N\t0\n",
      ".\t0\n",
      " Ber\t0\n",
      "atan\t0\n",
      " in\t0\n",
      " recognition\t0\n",
      " of\t0\n",
      " his\t0\n",
      " seminal\t10\n",
      " contributions\t0\n",
      " to\t0\n",
      " bi\t0\n",
      "oph\t0\n",
      "ysics\t0\n",
      " and\t0\n",
      " their\t0\n",
      " impact\t0\n",
      " on\t0\n",
      " our\t0\n",
      " understanding\t0\n",
      " of\t0\n",
      " charge\t0\n",
      " transport\t0\n",
      " in\t0\n",
      " biom\t0\n",
      "olecules\t0\n",
      ".\n",
      "\n",
      "\t0\n",
      "In\t0\n",
      "aug\t0\n",
      "ur\t0\n",
      "ated\t0\n",
      " in\t0\n",
      " \t0\n",
      "200\t0\n",
      "7\t0\n",
      " in\t0\n",
      " honor\t0\n",
      " of\t0\n",
      " the\t0\n",
      " Bi\t0\n",
      "opol\t0\n",
      "ym\t0\n",
      "ers\t0\n",
      " Found\t0\n",
      "ing\t1\n",
      " Editor\t0\n",
      ",\t0\n",
      " the\t0\n",
      " prize\t0\n",
      " is\t0\n",
      " awarded\t0\n",
      " for\t0\n",
      " outstanding\t0\n",
      " accomplishments\t0\n",
      "<end>\n",
      "\n",
      "\n",
      "Neuron 2\n",
      "Explanation of neuron 2 behavior: the main thing this neuron does is find the word “variant” and other words with the same ”vari” root\n",
      "Activations: \n",
      "<start>\n",
      "{\"\t0\n",
      "widget\t0\n",
      "Class\t0\n",
      "\":\"\t0\n",
      "Variant\t6\n",
      "Matrix\t0\n",
      "Widget\t0\n",
      "\",\"\t0\n",
      "back\t0\n",
      "order\t0\n",
      "Message\t0\n",
      "\":\"\t0\n",
      "Back\t0\n",
      "ordered\t0\n",
      "\",\"\t0\n",
      "back\t0\n",
      "order\t0\n",
      "Message\t0\n",
      "Single\t0\n",
      "Variant\t5\n",
      "\":\"\t0\n",
      "This\t0\n",
      " item\t0\n",
      " is\t0\n",
      " back\t0\n",
      "ordered\t0\n",
      ".\",\"\t0\n",
      "ordered\t0\n",
      "Selection\t0\n",
      "\":\t0\n",
      "true\t0\n",
      ",\"\t0\n",
      "product\t0\n",
      "Variant\t5\n",
      "Id\t0\n",
      "\":\t0\n",
      "0\t0\n",
      ",\"\t0\n",
      "variant\t6\n",
      "Id\t0\n",
      "Field\t0\n",
      "\":\"\t0\n",
      "product\t0\n",
      "196\t0\n",
      "39\t0\n",
      "_V\t5\n",
      "ariant\t5\n",
      "Id\t0\n",
      "\",\"\t0\n",
      "back\t0\n",
      "order\t0\n",
      "To\t0\n",
      "Message\t0\n",
      "Single\t0\n",
      "Variant\t4\n",
      "\":\"\t0\n",
      "This\t0\n",
      " item\t0\n",
      " is\t0\n",
      " back\t0\n",
      "ordered\t0\n",
      " and\t0\n",
      " is\t0\n",
      " expected\t0\n",
      " by\t0\n",
      " {\t0\n",
      "0\t0\n",
      "}.\t0\n",
      "\",\"\t0\n",
      "low\t0\n",
      "Price\t0\n",
      "\":\t0\n",
      "999\t0\n",
      "9\t0\n",
      ".\t0\n",
      "0\t0\n",
      ",\"\t0\n",
      "attribute\t0\n",
      "Indexes\t0\n",
      "\":[\t0\n",
      "],\"\t0\n",
      "productId\t0\n",
      "\":\t0\n",
      "196\t0\n",
      "39\t0\n",
      ",\"\t0\n",
      "price\t0\n",
      "V\t3\n",
      "ariance\t3\n",
      "\":\t0\n",
      "true\t0\n",
      ",\"\t0\n",
      "<end>\n",
      "<start>\n",
      "A\t0\n",
      " regular\t0\n",
      " look\t0\n",
      " at\t0\n",
      " the\t0\n",
      " ups\t0\n",
      " and\t0\n",
      " downs\t0\n",
      " of\t0\n",
      " variant\t9\n",
      " covers\t0\n",
      " in\t0\n",
      " the\t0\n",
      " comics\t0\n",
      " industry\t0\n",
      "…\n",
      "\n",
      "\t0\n",
      "Here\t0\n",
      " are\t0\n",
      " the\t0\n",
      " Lego\t0\n",
      " variant\t2\n",
      " sketch\t0\n",
      " covers\t0\n",
      " by\t0\n",
      " Leon\t0\n",
      "el\t0\n",
      " Cast\t0\n",
      "ell\t0\n",
      "ani\t0\n",
      " for\t0\n",
      " a\t0\n",
      " variety\t4\n",
      " of\t0\n",
      " Marvel\t0\n",
      " titles\t0\n",
      ",\t0\n",
      "<end>\n",
      "\n",
      "\n",
      "Now, we're going predict the activation of a new neuron on a single token, following the same rules as the examples above. Activations still range from 0 to 10.\n",
      "Neuron 3\n",
      "Explanation of neuron 3 behavior: the main thing this neuron does is find names and references that end with 'ac'.\n",
      "Text:\n",
      "B10 111 MONDAY, FEBRUARY 11, 2019 DONATE\n",
      "\n",
      "Last token in the text:\n",
      "ATE\n",
      "\n",
      "Last token activation, considering the token in the context in which it appeared in the text:\n",
      "8\n",
      "\n",
      "\n",
      "Neuron 4\n",
      "Explanation of neuron 4 behavior: the main thing this neuron does is find names and references that end with 'ac'.\n",
      "Text:\n",
      "Every individual philanthropist has a different giving strategy. But as we have discussed before , there are some overarching trends that can be sussed out, even among philanthropists in different countries. In the second edition of the BNP Paribas Individual Philanthropy Index , more than 400 philanthropists across the world with assets\n",
      "\n",
      "Last token in the text:\n",
      " assets\n",
      "\n",
      "Last token activation, considering the token in the context in which it appeared in the text:\n",
      "<|endofprompt|>\n"
     ]
    }
   ],
   "source": [
    "print('We\\'re studying neurons in a neural network. Each neuron looks for some particular thing in a short document. Look at  an explanation of what the neuron does, and try to predict its activations on a particular token.\\n\\nThe activation format is token<tab>activation, and activations range from 0 to 10. Most activations will be 0.\\n\\nNeuron 1\\nExplanation of neuron 1 behavior: the main thing this neuron does is find language related to something being groundbreaking\\nActivations: \\n<start>\\nThe\\t0\\n editors\\t0\\n of\\t0\\n Bi\\t0\\nopol\\t0\\nym\\t0\\ners\\t0\\n are\\t0\\n delighted\\t0\\n to\\t0\\n present\\t0\\n the\\t0\\n \\t0\\n201\\t0\\n8\\t0\\n Murray\\t0\\n Goodman\\t0\\n Memorial\\t0\\n Prize\\t0\\n to\\t0\\n Professor\\t0\\n David\\t0\\n N\\t0\\n.\\t0\\n Ber\\t0\\natan\\t0\\n in\\t0\\n recognition\\t0\\n of\\t0\\n his\\t0\\n seminal\\t10\\n contributions\\t0\\n to\\t0\\n bi\\t0\\noph\\t0\\nysics\\t0\\n and\\t0\\n their\\t0\\n impact\\t0\\n on\\t0\\n our\\t0\\n understanding\\t0\\n of\\t0\\n charge\\t0\\n transport\\t0\\n in\\t0\\n biom\\t0\\nolecules\\t0\\n.\\n\\n\\t0\\nIn\\t0\\naug\\t0\\nur\\t0\\nated\\t0\\n in\\t0\\n \\t0\\n200\\t0\\n7\\t0\\n in\\t0\\n honor\\t0\\n of\\t0\\n the\\t0\\n Bi\\t0\\nopol\\t0\\nym\\t0\\ners\\t0\\n Found\\t0\\ning\\t1\\n Editor\\t0\\n,\\t0\\n the\\t0\\n prize\\t0\\n is\\t0\\n awarded\\t0\\n for\\t0\\n outstanding\\t0\\n accomplishments\\t0\\n<end>\\n\\n\\nNeuron 2\\nExplanation of neuron 2 behavior: the main thing this neuron does is find the word “variant” and other words with the same ”vari” root\\nActivations: \\n<start>\\n{\"\\t0\\nwidget\\t0\\nClass\\t0\\n\":\"\\t0\\nVariant\\t6\\nMatrix\\t0\\nWidget\\t0\\n\",\"\\t0\\nback\\t0\\norder\\t0\\nMessage\\t0\\n\":\"\\t0\\nBack\\t0\\nordered\\t0\\n\",\"\\t0\\nback\\t0\\norder\\t0\\nMessage\\t0\\nSingle\\t0\\nVariant\\t5\\n\":\"\\t0\\nThis\\t0\\n item\\t0\\n is\\t0\\n back\\t0\\nordered\\t0\\n.\",\"\\t0\\nordered\\t0\\nSelection\\t0\\n\":\\t0\\ntrue\\t0\\n,\"\\t0\\nproduct\\t0\\nVariant\\t5\\nId\\t0\\n\":\\t0\\n0\\t0\\n,\"\\t0\\nvariant\\t6\\nId\\t0\\nField\\t0\\n\":\"\\t0\\nproduct\\t0\\n196\\t0\\n39\\t0\\n_V\\t5\\nariant\\t5\\nId\\t0\\n\",\"\\t0\\nback\\t0\\norder\\t0\\nTo\\t0\\nMessage\\t0\\nSingle\\t0\\nVariant\\t4\\n\":\"\\t0\\nThis\\t0\\n item\\t0\\n is\\t0\\n back\\t0\\nordered\\t0\\n and\\t0\\n is\\t0\\n expected\\t0\\n by\\t0\\n {\\t0\\n0\\t0\\n}.\\t0\\n\",\"\\t0\\nlow\\t0\\nPrice\\t0\\n\":\\t0\\n999\\t0\\n9\\t0\\n.\\t0\\n0\\t0\\n,\"\\t0\\nattribute\\t0\\nIndexes\\t0\\n\":[\\t0\\n],\"\\t0\\nproductId\\t0\\n\":\\t0\\n196\\t0\\n39\\t0\\n,\"\\t0\\nprice\\t0\\nV\\t3\\nariance\\t3\\n\":\\t0\\ntrue\\t0\\n,\"\\t0\\n<end>\\n<start>\\nA\\t0\\n regular\\t0\\n look\\t0\\n at\\t0\\n the\\t0\\n ups\\t0\\n and\\t0\\n downs\\t0\\n of\\t0\\n variant\\t9\\n covers\\t0\\n in\\t0\\n the\\t0\\n comics\\t0\\n industry\\t0\\n…\\n\\n\\t0\\nHere\\t0\\n are\\t0\\n the\\t0\\n Lego\\t0\\n variant\\t2\\n sketch\\t0\\n covers\\t0\\n by\\t0\\n Leon\\t0\\nel\\t0\\n Cast\\t0\\nell\\t0\\nani\\t0\\n for\\t0\\n a\\t0\\n variety\\t4\\n of\\t0\\n Marvel\\t0\\n titles\\t0\\n,\\t0\\n<end>\\n\\n\\nNow, we\\'re going predict the activation of a new neuron on a single token, following the same rules as the examples above. Activations still range from 0 to 10.\\nNeuron 3\\nExplanation of neuron 3 behavior: the main thing this neuron does is find names and references that end with \\'ac\\'.\\nText:\\nB10 111 MONDAY, FEBRUARY 11, 2019 DONATE\\n\\nLast token in the text:\\nATE\\n\\nLast token activation, considering the token in the context in which it appeared in the text:\\n8\\n\\n\\nNeuron 4\\nExplanation of neuron 4 behavior: the main thing this neuron does is find names and references that end with \\'ac\\'.\\nText:\\nEvery individual philanthropist has a different giving strategy. But as we have discussed before , there are some overarching trends that can be sussed out, even among philanthropists in different countries. In the second edition of the BNP Paribas Individual Philanthropy Index , more than 400 philanthropists across the world with assets\\n\\nLast token in the text:\\n assets\\n\\nLast token activation, considering the token in the context in which it appeared in the text:\\n<|endofprompt|>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "RateLimitError",
     "evalue": "Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRateLimitError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 7\u001b[0m\n\u001b[1;32m      3\u001b[0m os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOPENAI_API_KEY\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msk-proj-r-cxs65Z3DTrZDNV_I9pL8-zHACuP7tNGdrzWJLwy97malTTJyWRd7ij9ucjNYNg4FDXlfGsJrT3BlbkFJPT8sOHud-ToWymU2DMLXMGgjrIMmf-WbvGD3mbwD9clE7SnxxI5Ix3QEYV1v-8N2Zt3gLy4-0A\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      5\u001b[0m client \u001b[38;5;241m=\u001b[39m OpenAI()\n\u001b[0;32m----> 7\u001b[0m completion \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompletions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgpt-4o\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrole\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msystem\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mYou are a helpful assistant.\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrole\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mWrite a haiku about recursion in programming.\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m     14\u001b[0m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28mprint\u001b[39m(completion\u001b[38;5;241m.\u001b[39mchoices[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mmessage)\n",
      "File \u001b[0;32m~/miniconda3/envs/py3.9_autoInter/lib/python3.9/site-packages/openai/_utils/_utils.py:275\u001b[0m, in \u001b[0;36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    273\u001b[0m             msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    274\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[0;32m--> 275\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/py3.9_autoInter/lib/python3.9/site-packages/openai/resources/chat/completions.py:829\u001b[0m, in \u001b[0;36mCompletions.create\u001b[0;34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, response_format, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    788\u001b[0m \u001b[38;5;129m@required_args\u001b[39m([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m], [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m    789\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate\u001b[39m(\n\u001b[1;32m    790\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    826\u001b[0m     timeout: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m httpx\u001b[38;5;241m.\u001b[39mTimeout \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m NOT_GIVEN,\n\u001b[1;32m    827\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatCompletion \u001b[38;5;241m|\u001b[39m Stream[ChatCompletionChunk]:\n\u001b[1;32m    828\u001b[0m     validate_response_format(response_format)\n\u001b[0;32m--> 829\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    830\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/chat/completions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    831\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    832\u001b[0m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m    833\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmessages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    834\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    835\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43maudio\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43maudio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    836\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfrequency_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    837\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunction_call\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    838\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunctions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    839\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogit_bias\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    840\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    841\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_completion_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_completion_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    842\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    843\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmetadata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    844\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodalities\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodalities\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    845\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mn\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    846\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mparallel_tool_calls\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    847\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mprediction\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprediction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    848\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpresence_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    849\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mresponse_format\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    850\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mseed\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    851\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mservice_tier\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    852\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstop\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    853\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstore\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    854\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    855\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    856\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtemperature\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    857\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtool_choice\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    858\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtools\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    859\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_logprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    860\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_p\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    861\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    862\u001b[0m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    863\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCompletionCreateParams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    864\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    865\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    866\u001b[0m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[1;32m    867\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    868\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    869\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    870\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    871\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/py3.9_autoInter/lib/python3.9/site-packages/openai/_base_client.py:1278\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1264\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(\n\u001b[1;32m   1265\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1266\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1273\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1274\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[1;32m   1275\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[1;32m   1276\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[1;32m   1277\u001b[0m     )\n\u001b[0;32m-> 1278\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/miniconda3/envs/py3.9_autoInter/lib/python3.9/site-packages/openai/_base_client.py:955\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    952\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    953\u001b[0m     retries_taken \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m--> 955\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    956\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    957\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    958\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    959\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    960\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries_taken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    961\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/py3.9_autoInter/lib/python3.9/site-packages/openai/_base_client.py:1044\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1042\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m remaining_retries \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_retry(err\u001b[38;5;241m.\u001b[39mresponse):\n\u001b[1;32m   1043\u001b[0m     err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mclose()\n\u001b[0;32m-> 1044\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_retry_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1045\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1046\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1047\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries_taken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1048\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresponse_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1049\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1050\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1051\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1053\u001b[0m \u001b[38;5;66;03m# If the response is streamed then we need to explicitly read the response\u001b[39;00m\n\u001b[1;32m   1054\u001b[0m \u001b[38;5;66;03m# to completion before attempting to access the response text.\u001b[39;00m\n\u001b[1;32m   1055\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mis_closed:\n",
      "File \u001b[0;32m~/miniconda3/envs/py3.9_autoInter/lib/python3.9/site-packages/openai/_base_client.py:1093\u001b[0m, in \u001b[0;36mSyncAPIClient._retry_request\u001b[0;34m(self, options, cast_to, retries_taken, response_headers, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1089\u001b[0m \u001b[38;5;66;03m# In a synchronous context we are blocking the entire thread. Up to the library user to run the client in a\u001b[39;00m\n\u001b[1;32m   1090\u001b[0m \u001b[38;5;66;03m# different thread if necessary.\u001b[39;00m\n\u001b[1;32m   1091\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(timeout)\n\u001b[0;32m-> 1093\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1094\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1095\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1096\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries_taken\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1097\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1098\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1099\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/py3.9_autoInter/lib/python3.9/site-packages/openai/_base_client.py:1044\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1042\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m remaining_retries \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_retry(err\u001b[38;5;241m.\u001b[39mresponse):\n\u001b[1;32m   1043\u001b[0m     err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mclose()\n\u001b[0;32m-> 1044\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_retry_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1045\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1046\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1047\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries_taken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1048\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresponse_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1049\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1050\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1051\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1053\u001b[0m \u001b[38;5;66;03m# If the response is streamed then we need to explicitly read the response\u001b[39;00m\n\u001b[1;32m   1054\u001b[0m \u001b[38;5;66;03m# to completion before attempting to access the response text.\u001b[39;00m\n\u001b[1;32m   1055\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mis_closed:\n",
      "File \u001b[0;32m~/miniconda3/envs/py3.9_autoInter/lib/python3.9/site-packages/openai/_base_client.py:1093\u001b[0m, in \u001b[0;36mSyncAPIClient._retry_request\u001b[0;34m(self, options, cast_to, retries_taken, response_headers, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1089\u001b[0m \u001b[38;5;66;03m# In a synchronous context we are blocking the entire thread. Up to the library user to run the client in a\u001b[39;00m\n\u001b[1;32m   1090\u001b[0m \u001b[38;5;66;03m# different thread if necessary.\u001b[39;00m\n\u001b[1;32m   1091\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(timeout)\n\u001b[0;32m-> 1093\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1094\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1095\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1096\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries_taken\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1097\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1098\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1099\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/py3.9_autoInter/lib/python3.9/site-packages/openai/_base_client.py:1059\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1056\u001b[0m         err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mread()\n\u001b[1;32m   1058\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRe-raising status error\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1059\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_status_error_from_response(err\u001b[38;5;241m.\u001b[39mresponse) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1061\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_response(\n\u001b[1;32m   1062\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39mcast_to,\n\u001b[1;32m   1063\u001b[0m     options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1067\u001b[0m     retries_taken\u001b[38;5;241m=\u001b[39mretries_taken,\n\u001b[1;32m   1068\u001b[0m )\n",
      "\u001b[0;31mRateLimitError\u001b[0m: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"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\"\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"gpt-4o\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Write a haiku about recursion in programming.\"\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# os.environ[\"OPENAI_API_KEY\"] = \"36lz5h4ONaxXc\"\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"sk-GxUUtqZcVLu94WtfWBpU5vJHVSjITfyr2CxxnCT78CIMklZQ\"\n",
    "\n",
    "from neuron_explainer.activations.activation_records import calculate_max_activation\n",
    "from neuron_explainer.explanations.explainer import TokenActivationPairExplainer\n",
    "from neuron_explainer.explanations.prompt_builder import PromptFormat\n",
    "from neuron_explainer.explanations.puzzles import PUZZLES_BY_NAME\n",
    "\n",
    "\n",
    "EXPLAINER_MODEL_NAME = \"gpt-4\"\n",
    "\n",
    "explainer = TokenActivationPairExplainer(\n",
    "    model_name=EXPLAINER_MODEL_NAME,\n",
    "    prompt_format=PromptFormat.HARMONY_V4,\n",
    "    max_concurrent=1,\n",
    ")\n",
    "\n",
    "for puzzle_name, puzzle in PUZZLES_BY_NAME.items():\n",
    "    print(f\"{puzzle_name=}\")\n",
    "    puzzle_answer = puzzle.explanation\n",
    "    # Generate an explanation for the puzzle.\n",
    "    explanations = await explainer.generate_explanations(\n",
    "        all_activation_records=puzzle.activation_records,\n",
    "        max_activation=calculate_max_activation(puzzle.activation_records),\n",
    "        num_samples=1,\n",
    "    )\n",
    "    assert len(explanations) == 1\n",
    "    model_generated_explanation = explanations[0]\n",
    "    print(f\"{model_generated_explanation=}\")\n",
    "    print(f\"{puzzle_answer=}\\n\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3.9_autoInter",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
