{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now geting activations in features layer\n",
      "max_length=64, folder_path='./ori_136000it', model_dir='/data/jqliu/ML_jq/nanoGPT/out_ori/out_test', MEAN_ACT=False, NO_SAME_MAXTOKEN=False\n",
      "Resolving data files: 100%|█████████████████| 81/81 [00:00<00:00, 152760.17it/s]\n",
      "Loading dataset shards:   1%|▎                   | 1/80 [00:05<06:41,  5.08s/it]^C\n",
      "捕获到中断信号，正在清理资源...\n",
      "资源清理完毕，程序退出。\n",
      "Loading dataset shards:   1%|▎                   | 1/80 [00:07<09:27,  7.19s/it]\n"
     ]
    }
   ],
   "source": [
    "!CUDA_VISIBLE_DEVICES=9 python get_features_activations.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now processing activations of neurons\n",
      "max_length=64, info_dict_path='./ori_136000it/info_dict_neurons_activations__len_64.json'\n",
      "Resolving data files: 100%|█████████████████| 81/81 [00:00<00:00, 136660.75it/s]\n",
      "Loading dataset shards: 100%|███████████████████| 80/80 [01:14<00:00,  1.08it/s]\n",
      " those\n",
      " Clear\n",
      "ist\n",
      " to\n",
      " by\n",
      " series\n",
      " the\n",
      " our\n",
      " of\n",
      " of\n",
      " a\n",
      " Motor\n",
      "shard_0 finish!\n",
      "tokenizing shard 1 (num_proc=8):  10%| | 12849/125216 [00:02<00:14, 7598.26 exam^C\n",
      "tokenizing shard 1 (num_proc=8):  11%| | 13614/125216 [00:02<00:20, 5502.87 exam\n"
     ]
    }
   ],
   "source": [
    "!CUDA_VISIBLE_DEVICES=9 python process_activations.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "create_from_info_dict_neurons\n",
      "info_dict_path='./ori_136000it/info_dict_neurons_activations__len_64.json'\n",
      "neuron_records_path='./ori_136000it/neuron_records_neurons.json'\n",
      "layer_0, neuron_0 finished\n",
      "layer_0, neuron_300 finished\n",
      "layer_0, neuron_600 finished\n",
      "layer_0, neuron_900 finished\n",
      "layer_0, neuron_1200 finished\n",
      "layer_0, neuron_1500 finished\n",
      "layer_0, neuron_1800 finished\n",
      "layer_0, neuron_2100 finished\n",
      "layer_0, neuron_2400 finished\n",
      "layer_0, neuron_2700 finished\n",
      "layer_0, neuron_3000 finished\n",
      "layer_1, neuron_0 finished\n",
      "layer_1, neuron_300 finished\n",
      "layer_1, neuron_600 finished\n",
      "layer_1, neuron_900 finished\n",
      "layer_1, neuron_1200 finished\n",
      "layer_1, neuron_1500 finished\n",
      "layer_1, neuron_1800 finished\n",
      "layer_1, neuron_2100 finished\n",
      "layer_1, neuron_2400 finished\n",
      "layer_1, neuron_2700 finished\n",
      "layer_1, neuron_3000 finished\n",
      "layer_2, neuron_0 finished\n",
      "layer_2, neuron_300 finished\n",
      "layer_2, neuron_600 finished\n",
      "layer_2, neuron_900 finished\n",
      "layer_2, neuron_1200 finished\n",
      "layer_2, neuron_1500 finished\n",
      "layer_2, neuron_1800 finished\n",
      "layer_2, neuron_2100 finished\n",
      "layer_2, neuron_2400 finished\n",
      "layer_2, neuron_2700 finished\n",
      "layer_2, neuron_3000 finished\n",
      "layer_3, neuron_0 finished\n",
      "layer_3, neuron_300 finished\n",
      "layer_3, neuron_600 finished\n",
      "layer_3, neuron_900 finished\n",
      "layer_3, neuron_1200 finished\n",
      "layer_3, neuron_1500 finished\n",
      "layer_3, neuron_1800 finished\n",
      "layer_3, neuron_2100 finished\n",
      "layer_3, neuron_2400 finished\n",
      "layer_3, neuron_2700 finished\n",
      "layer_3, neuron_3000 finished\n",
      "layer_4, neuron_0 finished\n",
      "layer_4, neuron_300 finished\n",
      "layer_4, neuron_600 finished\n",
      "layer_4, neuron_900 finished\n",
      "layer_4, neuron_1200 finished\n",
      "layer_4, neuron_1500 finished\n",
      "layer_4, neuron_1800 finished\n",
      "layer_4, neuron_2100 finished\n",
      "layer_4, neuron_2400 finished\n",
      "layer_4, neuron_2700 finished\n",
      "layer_4, neuron_3000 finished\n",
      "layer_5, neuron_0 finished\n",
      "layer_5, neuron_300 finished\n",
      "layer_5, neuron_600 finished\n",
      "layer_5, neuron_900 finished\n",
      "layer_5, neuron_1200 finished\n",
      "layer_5, neuron_1500 finished\n",
      "layer_5, neuron_1800 finished\n",
      "layer_5, neuron_2100 finished\n",
      "layer_5, neuron_2400 finished\n",
      "layer_5, neuron_2700 finished\n",
      "layer_5, neuron_3000 finished\n",
      "layer_6, neuron_0 finished\n",
      "layer_6, neuron_300 finished\n",
      "layer_6, neuron_600 finished\n",
      "layer_6, neuron_900 finished\n",
      "layer_6, neuron_1200 finished\n",
      "layer_6, neuron_1500 finished\n",
      "layer_6, neuron_1800 finished\n",
      "layer_6, neuron_2100 finished\n",
      "layer_6, neuron_2400 finished\n",
      "layer_6, neuron_2700 finished\n",
      "layer_6, neuron_3000 finished\n",
      "layer_7, neuron_0 finished\n",
      "layer_7, neuron_300 finished\n",
      "layer_7, neuron_600 finished\n",
      "layer_7, neuron_900 finished\n",
      "layer_7, neuron_1200 finished\n",
      "layer_7, neuron_1500 finished\n",
      "layer_7, neuron_1800 finished\n",
      "layer_7, neuron_2100 finished\n",
      "layer_7, neuron_2400 finished\n",
      "layer_7, neuron_2700 finished\n",
      "layer_7, neuron_3000 finished\n",
      "layer_8, neuron_0 finished\n",
      "layer_8, neuron_300 finished\n",
      "layer_8, neuron_600 finished\n",
      "layer_8, neuron_900 finished\n",
      "layer_8, neuron_1200 finished\n",
      "layer_8, neuron_1500 finished\n",
      "layer_8, neuron_1800 finished\n",
      "layer_8, neuron_2100 finished\n",
      "layer_8, neuron_2400 finished\n",
      "layer_8, neuron_2700 finished\n",
      "layer_8, neuron_3000 finished\n",
      "layer_9, neuron_0 finished\n",
      "layer_9, neuron_300 finished\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "!python create_NeuronRecord.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! CUDA_VISIBLE_DEVICES=3 python generate_and_score.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import asyncio\n",
    "import logging\n",
    "\n",
    "# 设置环境变量\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"sk-FLe3r5MtADhHFlhvU8pfu8UcpTzo7l9r9xckT0slHQAp2aQe\"\n",
    "import sys \n",
    "sys.path.append(\"../\")\n",
    "neuron_records_path = \"./ori_136000it/neuron_records_neurons.json\"\n",
    "\n",
    "\n",
    "from neuron_explainer.activations.activation_records import calculate_max_activation\n",
    "from neuron_explainer.activations.activations import ActivationRecordSliceParams, load_neuron\n",
    "from neuron_explainer.explanations.calibrated_simulator import UncalibratedNeuronSimulator\n",
    "from neuron_explainer.explanations.explainer import TokenActivationPairExplainer\n",
    "from neuron_explainer.explanations.prompt_builder import PromptFormat\n",
    "from neuron_explainer.explanations.scoring import simulate_and_score\n",
    "from neuron_explainer.explanations.simulator import ExplanationTokenByTokenSimulator\n",
    "\n",
    "logging.basicConfig(filename='evaluation_ori_finetune_nonneg_feature_250000it_results.log', level=logging.INFO, format='%(message)s')\n",
    "\n",
    "EXPLAINER_MODEL_NAME = \"gpt-4\"\n",
    "SIMULATOR_MODEL_NAME = \"meta-llama/Meta-Llama-3-8B-Instruct\"\n",
    "layer_to_test = 11  # 要测试的层。如果测试的是最后一层features（计算logits之前的那一层），设置为0\n",
    "num_neurons = 3072  # 每一层神经元总数\n",
    "TEST_NUM = 2  # 要抽取测试的神经元数量\n",
    "SEED = 42\n",
    "# 设置随机种子\n",
    "random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def evaluate_neurons():\n",
    "    # 创建字典以记录结果\n",
    "    results = {}\n",
    "    total_score = 0.0\n",
    "\n",
    "    # 随机抽取神经元编号\n",
    "    random_neuron_indices = random.sample(range(num_neurons), TEST_NUM)\n",
    "    # random_neuron_indices = [142, 754, 104, 692, 758, 558, 89, 604, 432, 32, 30, 95, 223, 238, 517, 616, 27]\n",
    "    logging.info(\"=========================\")\n",
    "    logging.info(f\"{neuron_records_path=}\")\n",
    "    logging.info(f\"{random_neuron_indices=}\")\n",
    "    logging.info(\"=========================\")\n",
    "    print(\"=========================\")\n",
    "    print(f\"{neuron_records_path=}\")\n",
    "    print(f\"{random_neuron_indices=}\")\n",
    "    print(\"=========================\")\n",
    "\n",
    "    for i, neuron_idx in enumerate(random_neuron_indices, 1):\n",
    "        logging.info(f\"now evaluating feature_{neuron_idx}\")\n",
    "        print(f\"now evaluating feature_{neuron_idx}\")        \n",
    "        \n",
    "        # 加载神经元记录\n",
    "        neuron_record = load_neuron(layer_to_test, neuron_idx, neuron_records_path)\n",
    "        \n",
    "        # 获取激活记录\n",
    "        slice_params = ActivationRecordSliceParams(n_examples_per_split=5)\n",
    "        train_activation_records = neuron_record.train_activation_records(\n",
    "            activation_record_slice_params=slice_params\n",
    "        )\n",
    "        valid_activation_records = neuron_record.valid_activation_records(\n",
    "            activation_record_slice_params=slice_params\n",
    "        )\n",
    "\n",
    "        # 生成神经元解释\n",
    "        explainer = TokenActivationPairExplainer(\n",
    "            model_name=EXPLAINER_MODEL_NAME,\n",
    "            prompt_format=PromptFormat.HARMONY_V4,\n",
    "            max_concurrent=1,\n",
    "        )\n",
    "        explanations = await explainer.generate_explanations(\n",
    "            all_activation_records=train_activation_records,\n",
    "            max_activation=calculate_max_activation(train_activation_records),\n",
    "            num_samples=1,\n",
    "        )\n",
    "        assert len(explanations) == 1\n",
    "        explanation = explanations[0]\n",
    "        logging.info(f\"Neuron {neuron_idx} explanation: {explanation}\")\n",
    "        print(f\"Neuron {neuron_idx} explanation: {explanation}\")\n",
    "\n",
    "        # 模拟并计算得分\n",
    "        simulator = UncalibratedNeuronSimulator(\n",
    "            ExplanationTokenByTokenSimulator(\n",
    "                SIMULATOR_MODEL_NAME,\n",
    "                explanation,\n",
    "                max_concurrent=1,\n",
    "                prompt_format=PromptFormat.INSTRUCTION_FOLLOWING,\n",
    "            )\n",
    "        )\n",
    "        scored_simulation = await simulate_and_score(simulator, valid_activation_records)\n",
    "        score = scored_simulation.get_preferred_score()\n",
    "        logging.info(f\"Neuron {neuron_idx} score: {score:.2f}\")\n",
    "        print(f\"Neuron {neuron_idx} score: {score:.2f}\")\n",
    "        \n",
    "        # 将结果存入字典\n",
    "        results[neuron_idx] = {\n",
    "            \"explanation\": explanation,\n",
    "            \"score\": score\n",
    "        }\n",
    "        total_score += score\n",
    "\n",
    "    # 计算平均得分\n",
    "    average_score = total_score / TEST_NUM\n",
    "    logging.info(\"Finished\")\n",
    "    logging.info(f\"\\nAverage score for {TEST_NUM} neurons: {average_score:.2f}\")\n",
    "    print(\"Finished\")\n",
    "    print(f\"\\nAverage score for {TEST_NUM} neurons: {average_score:.2f}\")\n",
    "\n",
    "    # 打印所有结果\n",
    "    logging.info(\"\\nResults for each neuron:\")\n",
    "    print(\"\\nResults for each neuron:\")\n",
    "    for neuron_idx, data in results.items():\n",
    "        logging.info(f\"Neuron {neuron_idx}: Explanation: {data['explanation']}, Score: {data['score']:.2f}\")\n",
    "        print(f\"Neuron {neuron_idx}: Explanation: {data['explanation']}, Score: {data['score']:.2f}\")\n",
    "\n",
    "def main():\n",
    "    # 运行异步任务\n",
    "    asyncio.run(evaluate_neurons())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "asyncio.run() cannot be called from a running event loop",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[14], line 87\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmain\u001b[39m():\n\u001b[1;32m     86\u001b[0m     \u001b[38;5;66;03m# 运行异步任务\u001b[39;00m\n\u001b[0;32m---> 87\u001b[0m     \u001b[43masyncio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_neurons\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/py3.9_autoInter/lib/python3.12/asyncio/runners.py:190\u001b[0m, in \u001b[0;36mrun\u001b[0;34m(main, debug, loop_factory)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Execute the coroutine and return the result.\u001b[39;00m\n\u001b[1;32m    162\u001b[0m \n\u001b[1;32m    163\u001b[0m \u001b[38;5;124;03mThis function runs the passed coroutine, taking care of\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    186\u001b[0m \u001b[38;5;124;03m    asyncio.run(main())\u001b[39;00m\n\u001b[1;32m    187\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m events\u001b[38;5;241m.\u001b[39m_get_running_loop() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    189\u001b[0m     \u001b[38;5;66;03m# fail fast with short traceback\u001b[39;00m\n\u001b[0;32m--> 190\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    191\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124masyncio.run() cannot be called from a running event loop\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    193\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Runner(debug\u001b[38;5;241m=\u001b[39mdebug, loop_factory\u001b[38;5;241m=\u001b[39mloop_factory) \u001b[38;5;28;01mas\u001b[39;00m runner:\n\u001b[1;32m    194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m runner\u001b[38;5;241m.\u001b[39mrun(main)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: asyncio.run() cannot be called from a running event loop"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3.9_autoInter",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
