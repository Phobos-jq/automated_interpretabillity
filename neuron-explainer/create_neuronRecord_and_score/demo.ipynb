{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now geting activations in neurons\n",
      "max_length=64, folder_path='./ori_136000it', model_dir='/data/jqliu/ML_jq/nanoGPT/out_ori/out_test', MEAN_ACT=False\n",
      "Resolving data files: 100%|██████████████████| 81/81 [00:00<00:00, 65059.10it/s]\n",
      "Loading dataset shards: 100%|███████████████████| 80/80 [05:01<00:00,  3.77s/it]\n",
      "Now geting activations in neurons\n",
      "max_length=64, folder_path='./ori_136000it', model_dir='/data/jqliu/ML_jq/nanoGPT/out_ori/out_test', MEAN_ACT=False\n",
      "Now geting activations in neurons\n",
      "max_length=64, folder_path='./ori_136000it', model_dir='/data/jqliu/ML_jq/nanoGPT/out_ori/out_test', MEAN_ACT=False\n",
      "/home/jqliu/ML_jq/neuronExpainer/automated-interpretability/neuron-explainer/create_neuronRecord_and_score/get_activations.py:193: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(ckpt_path, map_location=device_gpt)\n",
      "/home/jqliu/ML_jq/neuronExpainer/automated-interpretability/neuron-explainer/create_neuronRecord_and_score/get_activations.py:193: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(ckpt_path, map_location=device_gpt)\n",
      "number of parameters: 123.59M\n",
      "number of parameters: 123.59M\n",
      "No meta.pkl found, assuming GPT-2 encodings...\n",
      "No meta.pkl found, assuming GPT-2 encodings...\n",
      "tokenizing shard 0 (num_proc=8): 100%|█| 125216/125216 [01:28<00:00, 1410.04 exa\n",
      "shard_0 is being processed\n",
      "tokenizing shard 1 (num_proc=8): 100%|█| 125216/125216 [01:29<00:00, 1404.72 exa\n",
      "shard_1 is being processed\n",
      "shard_0 batch_0 finished\n",
      "{'max_activation_value': 4.7365241050720215, 'max_token_idx': tensor(5584, device='cuda:0'), 'max_example_index': tensor(1455), 'max_token_index': tensor(41), 'activations': tensor([-0.1484, -0.1503,  0.0806,  0.7021,  0.2718, -0.1274, -0.0331, -0.1241,\n",
      "        -0.0757,  0.0090, -0.1484,  0.1093,  0.1496, -0.1676,  0.1661,  0.6423,\n",
      "        -0.1514, -0.0761,  0.4055, -0.1623,  0.3000,  0.4581, -0.1033,  0.0230,\n",
      "         0.3628, -0.0844, -0.1503, -0.1681,  0.3271,  0.4642,  0.1189,  0.0565,\n",
      "         0.3477, -0.0864, -0.0865,  0.1911, -0.0649, -0.0901,  1.2265,  0.2026,\n",
      "         0.7909,  4.7365, -0.0798,  0.4699,  0.6573,  0.4921, -0.1492,  0.2346,\n",
      "         0.1638,  0.6180,  0.6757,  0.9699,  2.2212,  0.0806,  0.4248, -0.1574,\n",
      "        -0.1058,  0.1739,  1.5381,  0.8589,  0.3707,  0.0561, -0.0848,  0.1517]), 'mean_activation': tensor(-100., device='cuda:0'), 'activations_first_sample': tensor([-0.1699, -0.1448, -0.1699, -0.1567, -0.1041, -0.1048, -0.1592, -0.1495,\n",
      "        -0.1214,  0.0731, -0.1465, -0.0124, -0.1686,  0.9398,  0.0360, -0.0281,\n",
      "        -0.0070,  0.4819, -0.1643, -0.1571, -0.1653, -0.1044, -0.1664,  0.3568,\n",
      "        -0.0646, -0.1654, -0.1249, -0.1560,  0.2994,  0.3660,  0.0684, -0.0997,\n",
      "        -0.1099,  0.6807,  0.4974, -0.1121, -0.0634, -0.0806, -0.0183, -0.0063,\n",
      "        -0.1699, -0.0494,  0.0217,  0.0161, -0.1393, -0.1577,  0.4418,  0.0143,\n",
      "        -0.1602, -0.1625, -0.1636,  0.2878, -0.1634, -0.0871,  0.9376, -0.1242,\n",
      "        -0.1202, -0.1589, -0.0705, -0.1610, -0.1448, -0.1074, -0.1543,  0.4547])}\n",
      "{'max_activation_value': 2.801767349243164, 'max_token_idx': tensor(3750, device='cuda:0'), 'max_example_index': tensor(1830), 'max_token_index': tensor(61), 'activations': tensor([-0.0497, -0.0262,  0.1600,  0.1005, -0.1329, -0.0663, -0.1023, -0.1127,\n",
      "         0.0590, -0.1504, -0.1472, -0.1272, -0.0881, -0.1031,  0.1629, -0.1663,\n",
      "        -0.1518,  0.5829,  0.0207,  0.0255,  0.5485, -0.1490,  1.7009, -0.1649,\n",
      "        -0.0425, -0.1425, -0.1676, -0.1700,  0.8513,  0.3184,  0.1269, -0.0718,\n",
      "         0.3456, -0.1100, -0.1076, -0.1699, -0.1190, -0.1509, -0.1641, -0.1587,\n",
      "        -0.1571, -0.1344, -0.1585,  0.8598,  0.1650, -0.1660, -0.0962,  1.2550,\n",
      "         1.2855,  0.2876,  0.8268,  0.0495, -0.1510,  0.4446, -0.1246, -0.0374,\n",
      "        -0.1650, -0.1673,  0.7094,  0.5319,  0.7481,  2.8018,  1.0586,  0.2802]), 'mean_activation': tensor(-100., device='cuda:0'), 'activations_first_sample': tensor([-0.1601, -0.1309,  0.1738, -0.0488, -0.0198, -0.0875, -0.0465,  0.0334,\n",
      "        -0.1026, -0.0209, -0.0215, -0.0214, -0.0274, -0.0885, -0.1222, -0.0124,\n",
      "        -0.1053, -0.0024, -0.1061, -0.1397, -0.1671, -0.0052, -0.0086, -0.0263,\n",
      "        -0.1165, -0.1520, -0.1076, -0.0383, -0.0116, -0.1277, -0.0464, -0.0275,\n",
      "        -0.0004, -0.0039, -0.0057, -0.1696, -0.1642, -0.0932, -0.1686, -0.1471,\n",
      "        -0.1300, -0.0602, -0.1066, -0.1376, -0.0252, -0.1625, -0.0819, -0.1621,\n",
      "        -0.1480, -0.1035, -0.1697, -0.0266, -0.1534, -0.1695, -0.0110, -0.1700,\n",
      "        -0.0522, -0.0131, -0.0653, -0.0457, -0.0370, -0.1333, -0.1055, -0.0067])}\n",
      "/home/jqliu/ML_jq/neuronExpainer/automated-interpretability/neuron-explainer/create_neuronRecord_and_score/get_activations.py:193: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(ckpt_path, map_location=device_gpt)\n",
      "shard_0 batch_1 finished\n",
      "shard_0 batch_2 finished\n",
      "number of parameters: 123.59M\n",
      "No meta.pkl found, assuming GPT-2 encodings...\n",
      "tokenizing shard 3 (num_proc=8):  70%|▋| 87397/125216 [00:47<00:13, 2854.95 examshard_0 batch_3 finished\n",
      "tokenizing shard 3 (num_proc=8): 100%|▉| 125060/125216 [01:31<00:00, 328.75 examshard_0 batch_4 finished\n",
      "shard_0 batch_5 finished\n",
      "shard_0 batch_6 finished\n",
      "^C\n",
      "捕获到中断信号，正在清理资源...\n",
      "捕获到中断信号，正在清理资源...\n"
     ]
    }
   ],
   "source": [
    "!CUDA_VISIBLE_DEVICES=9 python get_activations.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!CUDA_VISIBLE_DEVICES=9 python process_activations.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!create_NeuronRecord.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import asyncio\n",
    "import logging\n",
    "\n",
    "# 设置环境变量\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"sk-FLe3r5MtADhHFlhvU8pfu8UcpTzo7l9r9xckT0slHQAp2aQe\"\n",
    "import sys \n",
    "sys.path.append(\"/home/jqliu/ML_jq/neuronExpainer/automated-interpretability/neuron-explainer\")\n",
    "neuron_records_path = \"/data/jqliu/ML_jq/nanoGPT/activations/ori_finetune_nonneg_feature_250000it/neuron_records_featuress.json\"\n",
    "\n",
    "\n",
    "from neuron_explainer.activations.activation_records import calculate_max_activation\n",
    "from neuron_explainer.activations.activations import ActivationRecordSliceParams, load_neuron\n",
    "from neuron_explainer.explanations.calibrated_simulator import UncalibratedNeuronSimulator\n",
    "from neuron_explainer.explanations.explainer import TokenActivationPairExplainer\n",
    "from neuron_explainer.explanations.prompt_builder import PromptFormat\n",
    "from neuron_explainer.explanations.scoring import simulate_and_score\n",
    "from neuron_explainer.explanations.simulator import ExplanationTokenByTokenSimulator\n",
    "\n",
    "logging.basicConfig(filename='evaluation_ori_finetune_nonneg_feature_250000it_results.log', level=logging.INFO, format='%(message)s')\n",
    "\n",
    "EXPLAINER_MODEL_NAME = \"gpt-4\"\n",
    "SIMULATOR_MODEL_NAME = \"meta-llama/Meta-Llama-3-8B-Instruct\"\n",
    "layer_to_test = 11  # 要测试的层。如果测试的是最后一层features（计算logits之前的那一层），设置为0\n",
    "num_neurons = 3072  # 每一层神经元总数\n",
    "TEST_NUM = 2  # 要抽取测试的神经元数量\n",
    "SEED = 42\n",
    "# 设置随机种子\n",
    "random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def evaluate_neurons():\n",
    "    # 创建字典以记录结果\n",
    "    results = {}\n",
    "    total_score = 0.0\n",
    "\n",
    "    # 随机抽取神经元编号\n",
    "    random_neuron_indices = random.sample(range(num_neurons), TEST_NUM)\n",
    "    # random_neuron_indices = [142, 754, 104, 692, 758, 558, 89, 604, 432, 32, 30, 95, 223, 238, 517, 616, 27]\n",
    "    logging.info(\"=========================\")\n",
    "    logging.info(f\"{neuron_records_path=}\")\n",
    "    logging.info(f\"{random_neuron_indices=}\")\n",
    "    logging.info(\"=========================\")\n",
    "    print(\"=========================\")\n",
    "    print(f\"{neuron_records_path=}\")\n",
    "    print(f\"{random_neuron_indices=}\")\n",
    "    print(\"=========================\")\n",
    "\n",
    "    for i, neuron_idx in enumerate(random_neuron_indices, 1):\n",
    "        logging.info(f\"now evaluating feature_{neuron_idx}\")\n",
    "        print(f\"now evaluating feature_{neuron_idx}\")        \n",
    "        \n",
    "        # 加载神经元记录\n",
    "        neuron_record = load_neuron(layer_to_test, neuron_idx, neuron_records_path)\n",
    "        \n",
    "        # 获取激活记录\n",
    "        slice_params = ActivationRecordSliceParams(n_examples_per_split=5)\n",
    "        train_activation_records = neuron_record.train_activation_records(\n",
    "            activation_record_slice_params=slice_params\n",
    "        )\n",
    "        valid_activation_records = neuron_record.valid_activation_records(\n",
    "            activation_record_slice_params=slice_params\n",
    "        )\n",
    "\n",
    "        # 生成神经元解释\n",
    "        explainer = TokenActivationPairExplainer(\n",
    "            model_name=EXPLAINER_MODEL_NAME,\n",
    "            prompt_format=PromptFormat.HARMONY_V4,\n",
    "            max_concurrent=1,\n",
    "        )\n",
    "        explanations = await explainer.generate_explanations(\n",
    "            all_activation_records=train_activation_records,\n",
    "            max_activation=calculate_max_activation(train_activation_records),\n",
    "            num_samples=1,\n",
    "        )\n",
    "        assert len(explanations) == 1\n",
    "        explanation = explanations[0]\n",
    "        logging.info(f\"Neuron {neuron_idx} explanation: {explanation}\")\n",
    "        print(f\"Neuron {neuron_idx} explanation: {explanation}\")\n",
    "\n",
    "        # 模拟并计算得分\n",
    "        simulator = UncalibratedNeuronSimulator(\n",
    "            ExplanationTokenByTokenSimulator(\n",
    "                SIMULATOR_MODEL_NAME,\n",
    "                explanation,\n",
    "                max_concurrent=1,\n",
    "                prompt_format=PromptFormat.INSTRUCTION_FOLLOWING,\n",
    "            )\n",
    "        )\n",
    "        scored_simulation = await simulate_and_score(simulator, valid_activation_records)\n",
    "        score = scored_simulation.get_preferred_score()\n",
    "        logging.info(f\"Neuron {neuron_idx} score: {score:.2f}\")\n",
    "        print(f\"Neuron {neuron_idx} score: {score:.2f}\")\n",
    "        \n",
    "        # 将结果存入字典\n",
    "        results[neuron_idx] = {\n",
    "            \"explanation\": explanation,\n",
    "            \"score\": score\n",
    "        }\n",
    "        total_score += score\n",
    "\n",
    "    # 计算平均得分\n",
    "    average_score = total_score / TEST_NUM\n",
    "    logging.info(\"Finished\")\n",
    "    logging.info(f\"\\nAverage score for {TEST_NUM} neurons: {average_score:.2f}\")\n",
    "    print(\"Finished\")\n",
    "    print(f\"\\nAverage score for {TEST_NUM} neurons: {average_score:.2f}\")\n",
    "\n",
    "    # 打印所有结果\n",
    "    logging.info(\"\\nResults for each neuron:\")\n",
    "    print(\"\\nResults for each neuron:\")\n",
    "    for neuron_idx, data in results.items():\n",
    "        logging.info(f\"Neuron {neuron_idx}: Explanation: {data['explanation']}, Score: {data['score']:.2f}\")\n",
    "        print(f\"Neuron {neuron_idx}: Explanation: {data['explanation']}, Score: {data['score']:.2f}\")\n",
    "\n",
    "def main():\n",
    "    # 运行异步任务\n",
    "    asyncio.run(evaluate_neurons())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3.9_autoInter",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
